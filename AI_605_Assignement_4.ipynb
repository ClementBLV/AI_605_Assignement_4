{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReonT_YasRSx"
   },
   "source": [
    "# KAIST AI605 Assignment 4: Question Answering with BERT and T5\n",
    "\n",
    "TA in charge: Miyoung Ko (miyoungko@kaist.ac.kr)\n",
    "\n",
    "**Due date**:  June 7 (Tue) 11:00pm, 2022  \n",
    "\n",
    "\n",
    "## Your Submission\n",
    "If you are a KAIST student, you will submit your assignment via [KLMS](https://klms.kaist.ac.kr). If you are a NAVER student, you will submit via [Google Form](https://forms.gle/FSng5HUwtQinTFAU8). \n",
    "\n",
    "You need to submit both (1) .ipynb file (needs to be fully executable on CoLab), and (2) a pdf of the file.\n",
    "\n",
    "Use in-line LaTeX (see below) for mathematical expressions. Collaboration among students is allowed but it is not a group assignment so make sure your answer and code are your own. Make sure to mention your collaborators in your assignment with their names and their student ids.\n",
    "\n",
    "## Grading\n",
    "The entire assignment is out of 20 points.. For every late day, your grade will be deducted by 2 points (KAIST students only). You can use one of your no-penalty late days (7 days in total). Make sure to mention this in your submission. You will receive a grade of zero if you submit after 7 days.\n",
    "\n",
    "\n",
    "## Environment\n",
    "You will need Python 3.7+ and PyTorch 1.9+, which are already available on Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "9qwta269rqLQ",
    "outputId": "60aeafe3-4b3a-45ee-b71c-6d2235d6e66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.13\n",
      "torch 1.11.0+cu113\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "import torch\n",
    "\n",
    "print(\"python\", python_version())\n",
    "print(\"torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUzrauQMk8dE"
   },
   "source": [
    "## 1. Hugging Face Library\n",
    "\n",
    "In this assignment, you will  use `transformers` library by Hugging Face. The library provides you an easy way to utilize diverse pretrained language models. \n",
    "You should be familiar with the library by now, but if not, please go over Lab 09 and Lab 10, and/or Hugging Face's sequence classification tutorial (https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/training.ipynb). Also, you code might get quite long at the end, so it is recommended to use a library like PyTorch Lightning (https://www.pytorchlightning.ai/) that helps you organize yoru code.\n",
    "\n",
    "For this assignment, make sure to install both `transformers` and `datasets` packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "efmyiqBuljdq"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ttTrzNSqjIXH"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22H4t9BjlCTy"
   },
   "source": [
    "> **Problem 1.1** *(1 point)* Put your favorite emoji here 😇\n",
    "https://getemoji.com/\n",
    "\n",
    "Your favorite emoji: 💩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGEBNOovjgvI"
   },
   "source": [
    "## 2. Machine Reading Comprehension with BERT\n",
    "\n",
    "Here, you will formulate machine reading comprehension as a token classification problem, which means you attempt to predict the start and the end position of the answer in the context. In other words, you will create a d-by-2 linear layer on top of each token-level output of BERT (where the question and the context are concatenated), and you will use each dimension of the linear layer's output for the logits of the start and the end positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6qYDaPYkvZ5"
   },
   "source": [
    "> **Problem 2.1** *(3 points)* Finetune `bert-base-cased` model for `squad` question answering dataset and report the accuracy on the validation set. For convenience, ignore examples that have more than 256 tokens after tokenization.  *Hint*: If you are having difficulty in implementation, take a peek at  (but do not copy!) https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering, though keep in mind that the answer extraction module there is quite complex to maximize accuracy. In this assignment, however, consider simplifying it at the cost of (a bit of) accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFeDM85rdw3Y"
   },
   "source": [
    "# BERT Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--PzT0K86T5p"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nvkz7ZbW7Sza"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UFmEHlcjKPrA"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TYcmOoDJFc-I"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0,
     "referenced_widgets": [
      "16de154b4eb543c7966079ab84f4853b",
      "3f3393ddb6a74668b9f189e19d6911c7",
      "9d49a74ca9af4e78b331b9a755d7c15f",
      "0906b302849f4f8fae7121b35c9db9e4",
      "f32d2bb8c2a744e6b00e164ef74a1d2a",
      "ab27e5bab14e4af8aa5d93361951ea4f",
      "1f29dccde956435783fceaa35908f348",
      "466bca6a7696473daabac92cb9b03bbc",
      "c713cbf0b83c47c6accfe99f60afaf0d",
      "fee7701d21ad4bffbbd31bd0605bc6c8",
      "4588b2549d424120bccd3e8fd4b331d7"
     ]
    },
    "id": "rgkWoCwMgt4z",
    "outputId": "c53d0ed8-8bf8-4efd-f3e1-4688a85469e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16de154b4eb543c7966079ab84f4853b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
      " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
      "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
      "            'Immediately in front of the Main Building and facing it, is a '\n",
      "            'copper statue of Christ with arms upraised with the legend '\n",
      "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
      "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
      "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
      "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
      "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
      "            'main drive (and in a direct line that connects through 3 statues '\n",
      "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
      " 'id': '5733be284776f41900661182',\n",
      " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
      "             'France?',\n",
      " 'title': 'University_of_Notre_Dame'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "squad_dataset = load_dataset('squad')\n",
    "pprint(squad_dataset['train'][0]) # 'context' contains the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6KSHZ-16YDJ"
   },
   "source": [
    "##  Data set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Ts-mCVqphciH",
    "outputId": "05cd9a78-bf14-4881-f965-f9ab2bdaf71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saint Bernadette Soubirous']\n"
     ]
    }
   ],
   "source": [
    "# training set \n",
    "context  = squad_dataset['train']['context'][0:30000]\n",
    "questions= squad_dataset['train']['question'][0:30000]\n",
    "answers  = squad_dataset['train']['answers'][0:30000]\n",
    "print(answers[0]['text'])\n",
    "\n",
    "# validation set \n",
    "context_v  = squad_dataset['validation']['context'][0:30000]\n",
    "questions_v= squad_dataset['validation']['question'][0:30000]\n",
    "answers_v  = squad_dataset['validation']['answers'][0:30000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bm2hQFl9kDv8"
   },
   "outputs": [],
   "source": [
    "def process(context, questions, answers):\n",
    "    \"\"\"document is a list of sentences, be carefull anwser is a dictionnary with start token \n",
    "\"\"\"\n",
    "    context_dict = {}\n",
    "    light_context= []\n",
    "    query_answers= []\n",
    "    answers_l    = []\n",
    "    count        = 0\n",
    "\n",
    "    for context, question, answer in zip(context, questions, answers):\n",
    "        if context in context_dict:\n",
    "            context_id = context_dict[context]\n",
    "        else:\n",
    "            context_id = count\n",
    "            context_dict[context] = count\n",
    "            count += 1\n",
    "            light_context.append(context)\n",
    "        query_answers.append([context_id, question, answer ])\n",
    "        answers_l.append(answer)\n",
    "    return light_context, query_answers, answers_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "fYeuNLtil3z-",
    "outputId": "452b2f88-e0a6-4255-9bda-818056ea3271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6654,)\n"
     ]
    }
   ],
   "source": [
    "light_context    , light_qestions    , light_answers      = process(context  , questions  , answers)\n",
    "light_context_val, light_qestions_val, light_answers_val  = process(context_v, questions_v, answers_v)\n",
    "\n",
    "print(np.shape(light_context)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YuV9Vk508e8Q",
    "outputId": "da1dd345-5ebb-4c00-a809-48eb427747e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "answer :   ['Saint Bernadette Soubirous'] {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n",
      "contex :   Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "#Small test\n",
    "print(\"question: \", light_qestions[0][1])\n",
    "print(\"answer :  \", light_qestions[0][2]['text'], light_answers[0])\n",
    "print(\"contex :  \" , light_context[light_qestions[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "n60jhF2Dt_oD",
    "outputId": "6a18f283-413a-4837-9a11-7f5e5a02b0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  How much did Beyonce initially contribute to the foundation?\n",
      "answer :   ['$250,000'] {'text': ['$250,000'], 'answer_start': [190], 'answer_end': [191]}\n",
      "contex :   After Hurricane Katrina in 2005, Beyoncé and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which Beyoncé contributed an initial $250,000. The foundation has since expanded to work with other charities in the city, and also provided relief following Hurricane Ike three years later.\n"
     ]
    }
   ],
   "source": [
    "## Add the end index to the answers and correct the wrong start index : \n",
    "\n",
    "def start_end_index(contexts, answers): \n",
    "  \"\"\" Be carefull answers can be either a list of plosible elements or a list of one element \"\"\"\n",
    "  # firstly we goes throught each of them : \n",
    "  for context, answer in zip (contexts, answers): \n",
    "    answer_text = answer['text']\n",
    "    answer_start= answer['answer_start'][0]\n",
    "    answer_end  = answer_start + len(answer_text)  # ideal end token if there is no mistakes in the start token\n",
    "    if len(context[answer_start:answer_end]) == len(answer_text): # every thing is fine\n",
    "      answer['answer_end']= [answer_end]\n",
    "    else:  \n",
    "      for index_shift in [1,2]:  # it is said that it is usually shif from one or two characters : \n",
    "        if context[answer_start-index_shift : answer_end - index_shift] == len(answer_text): # every thing is fine\n",
    "          answer['answer_start']= [answer_start-index_shift]\n",
    "          answer['answer_end']= [answer_end -index_shift]\n",
    "          print(answer)\n",
    "\n",
    "        elif context[answer_start + index_shift :answer_end + index_shift] == len(answer_text): # every thing is fine\n",
    "          answer['answer_start']= [answer_start+index_shift]\n",
    "          answer['answer_end']= [answer_end + index_shift]\n",
    "\n",
    "start_end_index(light_context, light_answers)\n",
    "#Small test\n",
    "print(\"question: \", light_qestions[1000][1])\n",
    "print(\"answer :  \", light_qestions[1000][2]['text'], light_answers[1000])\n",
    "print(\"contex :  \" , light_context[light_qestions[1000][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hDOBz0AYZz1V"
   },
   "outputs": [],
   "source": [
    "def group_matrix(light_context,light_questions): \n",
    "  #contexts = [ [] for i in range( len(light_context))]\n",
    "  #answers  = [[] for i in range( len(light_context))]\n",
    "  #questions= [[] for i in range( len(light_context))]\n",
    "  contexts = []\n",
    "  answers  = []\n",
    "  questions= []\n",
    "  i = 0\n",
    "  for q in light_questions : \n",
    "    contexts.append(light_context[q[0]])\n",
    "    answers.append(q[2])\n",
    "    questions.append(q[1])\n",
    "  return contexts, answers, questions \n",
    "\n",
    "context_matrix  , answer_matrix  , question_matrix   = group_matrix(light_context,light_qestions)\n",
    "context_matrix_v, answer_matrix_v, questions_matrix_v = group_matrix(light_context_val,light_qestions_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "3YXBMja46Umk",
    "outputId": "301dfade-e9f2-415e-f1d2-7b602bec540d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n",
      "(30000,)\n",
      "(30000,)\n",
      "['To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
      " 'What is in front of the Notre Dame Main Building?',\n",
      " 'The Basilica of the Sacred heart at Notre Dame is beside to which structure?']\n",
      "['Architecturally, the school has a Catholic character. Atop the Main '\n",
      " \"Building's gold dome is a golden statue of the Virgin Mary. Immediately in \"\n",
      " 'front of the Main Building and facing it, is a copper statue of Christ with '\n",
      " 'arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main '\n",
      " 'Building is the Basilica of the Sacred Heart. Immediately behind the '\n",
      " 'basilica is the Grotto, a Marian place of prayer and reflection. It is a '\n",
      " 'replica of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
      " 'appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive '\n",
      " '(and in a direct line that connects through 3 statues and the Gold Dome), is '\n",
      " 'a simple, modern stone statue of Mary.',\n",
      " 'Architecturally, the school has a Catholic character. Atop the Main '\n",
      " \"Building's gold dome is a golden statue of the Virgin Mary. Immediately in \"\n",
      " 'front of the Main Building and facing it, is a copper statue of Christ with '\n",
      " 'arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main '\n",
      " 'Building is the Basilica of the Sacred Heart. Immediately behind the '\n",
      " 'basilica is the Grotto, a Marian place of prayer and reflection. It is a '\n",
      " 'replica of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
      " 'appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive '\n",
      " '(and in a direct line that connects through 3 statues and the Gold Dome), is '\n",
      " 'a simple, modern stone statue of Mary.',\n",
      " 'Architecturally, the school has a Catholic character. Atop the Main '\n",
      " \"Building's gold dome is a golden statue of the Virgin Mary. Immediately in \"\n",
      " 'front of the Main Building and facing it, is a copper statue of Christ with '\n",
      " 'arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main '\n",
      " 'Building is the Basilica of the Sacred Heart. Immediately behind the '\n",
      " 'basilica is the Grotto, a Marian place of prayer and reflection. It is a '\n",
      " 'replica of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
      " 'appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive '\n",
      " '(and in a direct line that connects through 3 statues and the Gold Dome), is '\n",
      " 'a simple, modern stone statue of Mary.']\n",
      "[{'answer_end': [516],\n",
      "  'answer_start': [515],\n",
      "  'text': ['Saint Bernadette Soubirous']},\n",
      " {'answer_end': [189],\n",
      "  'answer_start': [188],\n",
      "  'text': ['a copper statue of Christ']},\n",
      " {'answer_end': [280], 'answer_start': [279], 'text': ['the Main Building']}]\n"
     ]
    }
   ],
   "source": [
    "pprint(np.shape(question_matrix))\n",
    "pprint(np.shape(context_matrix))\n",
    "pprint(np.shape(answer_matrix))\n",
    "\n",
    "pprint(question_matrix[0:3])\n",
    "pprint(context_matrix[0:3])\n",
    "pprint(answer_matrix[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zCl_uJ-4tk91",
    "outputId": "8f875118-e343-43f3-ac21-d93947504a5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In what year did the team lead by Knute Rockne win the Rose Bowl?',\n",
       " {'answer_end': [355], 'answer_start': [354], 'text': ['1925']},\n",
       " 'One of the main driving forces in the growth of the University was its football team, the Notre Dame Fighting Irish. Knute Rockne became head coach in 1918. Under Rockne, the Irish would post a record of 105 wins, 12 losses, and five ties. During his 13 years the Irish won three national championships, had five undefeated seasons, won the Rose Bowl in 1925, and produced players such as George Gipp and the \"Four Horsemen\". Knute Rockne has the highest winning percentage (.881) in NCAA Division I/FBS football history. Rockne\\'s offenses employed the Notre Dame Box and his defenses ran a 7–2–2 scheme. The last game Rockne coached was on December 14, 1930 when he led a group of Notre Dame all-stars against the New York Giants in New York City.')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_info(light_context, light_qestions,i): \n",
    "  \"return question, answer context\"\n",
    "  return (light_qestions[i][1], light_qestions[i][2], light_context[light_qestions[i][0]])\n",
    "get_info(light_context, light_qestions,100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aka18BGkZy5P"
   },
   "outputs": [],
   "source": [
    "## Make a dataset class to use the dataloader method after : \n",
    "import torch \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "  \n",
    "  def __getitem__(self, index) -> dict: \n",
    "    return ({ key: torch.tensor(value[index]) for key, value in self.encodings.items() })\n",
    "  \n",
    "  def __len__(self)->int: \n",
    "    return (len(self.encodings.input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CEeXYKV6g6n"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dd5375cce8aa4ac5883a7c82be814954",
      "61f45d81147a40eba63f13ac64b2ae9b",
      "20bd851c682f415eb276d0f5bf42fa3d",
      "ba10ef5a093e4200a93f6ea466520683",
      "6083ca67e00b4866aafc60e90f84c60c",
      "274c840571304321bda7f84b4f0a1b74",
      "89c98d6cc4b541bb899258d3c0b0d864",
      "81539b6089144f7fa15e5ddf9d7031ef",
      "4a60e090289d47cda36ff4d04e015480",
      "dfda21f61f594f9db7d4f68bf59625cc",
      "6ab95d30bb3846e8b8fdff783bfa1d26",
      "2a98440904c1411ebe15f36cb0aff226",
      "b1ebb88661ca4bd59455e5aa6ffadcdf",
      "d52b2b451a3a4b9bbfbd61aee9499229",
      "dc03d053690f4c0d832e9c9ef906cacd",
      "2b103f6133ac42ffbe9d61f5d2c09d31",
      "c0c1537770f8462ebe3cdb0723b3e154",
      "6b17b0751cfb47109523569c101a8df5",
      "7c98fc1e7e2449959776ffb59365bf5c",
      "9ef2960cc03a4622b398eb95a38da4a1",
      "f145b7bb1ea34075bd86e7f223629fca",
      "367ffeab7c8b48038aa3f6f044d00810",
      "7928ab3ea0924c468ddb34fe14178cb1",
      "e0aa3b4f26ea4b71b81aa7f8f24c4be3",
      "619dc782eb834296b09c462e132ae20d",
      "07169dfe8c4b4e0f86438e7f04f9fc02",
      "97bb563104394ac6a9f50e4411c39d5e",
      "d02dbe7dc6fe4974b940d980aeaa3fcf",
      "c7cd19f054af485cb863d67f03b22961",
      "471d168f549447ffbb5b009f830cf831",
      "1d8ee50f0c9c4264ac26fdaf18978d5a",
      "cdcbb98dbef44e99a59ee3f6fefa26e3",
      "5cbfee70b03a4e42aaa29d64793b4990"
     ]
    },
    "id": "LAFSvUXlOke6",
    "outputId": "859fbbaa-80d8-494f-8da1-5142ef76f3ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5375cce8aa4ac5883a7c82be814954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a98440904c1411ebe15f36cb0aff226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7928ab3ea0924c468ddb34fe14178cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "##### Tokenizer : \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "#context_matrix, answer_matrix, question_matrix\n",
    "\n",
    "encoded_train = tokenizer(context_matrix, question_matrix, truncation=True,  padding='max_length')\n",
    "encoded_val   = tokenizer(context_matrix_v, questions_matrix_v,truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7ll9FfBFgh1",
    "outputId": "8cf7aec6-3453-4f09-e47d-23ef23065803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "30000\n",
      "[101, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959]\n"
     ]
    }
   ],
   "source": [
    "# element retruned \n",
    "print(encoded_train.keys())\n",
    "print(len(encoded_train['input_ids']))\n",
    "pprint(encoded_train['input_ids'][0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jx_Fdf4197Ve",
    "outputId": "b43e8f15-f88f-4a87-ac0a-cf32cde582c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_answer [101, 1565, 102]\n",
      "answre [1565]\n",
      "text ['[CLS]', 'At', 'the', '52', '##nd', 'Annual', 'Grammy', 'Awards', ',', 'Beyoncé', 'received', 'ten', 'nominations', ',', 'including', 'Album', 'of', 'the', 'Year', 'for', 'I', 'Am', '.', '.', '.', 'Sasha', 'Fi', '##er', '##ce', ',', 'Record', 'of', 'the', 'Year', 'for', '\"', 'Hal', '##o', '\"', ',', 'and', 'Song', 'of', 'the', 'Year', 'for', '\"', 'Single', 'Ladies', '(', 'Put', 'a', 'Ring', 'on', 'It', ')', '\"', ',', 'among', 'others', '.', 'She', 'tied', 'with', 'Lau', '##ryn', 'Hill', 'for', 'most', 'Grammy', 'nominations', 'in', 'a', 'single', 'year', 'by', 'a', 'female', 'artist', '.', 'In', '2010', ',', 'Beyoncé', 'was', 'featured', 'on', 'Lady', 'Gaga', \"'\", 's', 'single', '\"', 'Telephone', '\"', 'and', 'its', 'music', 'video', '.', 'The', 'song', 'topped', 'the', 'US', 'Pop', 'Songs', 'chart', ',', 'becoming', 'the', 'sixth', 'number', '-', 'one', 'for', 'both', 'Beyoncé', 'and', 'Gaga', ',', 'tying', 'them', 'with', 'Maria', '##h', 'Carey', 'for', 'most', 'number', '-', 'ones', 'since', 'the', 'Nielsen', 'Top', '40', 'airplay', 'chart', 'launched', 'in', '1992', '.', '\"', 'Telephone', '\"', 'received', 'a', 'Grammy', 'Award', 'nomination', 'for', 'Best', 'Pop', 'Col', '##la', '##bor', '##ation', 'with', 'Vocals', '.', '[SEP]', 'How', 'many', 'number', 'one', 'singles', 'did', 'Bey', '##on', '##ce', 'now', 'have', 'after', 'the', 'song', '\"', 'Telephone', '\"', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "anser ['[CLS]', 'six', '[SEP]']\n",
      "answer ['six']\n"
     ]
    }
   ],
   "source": [
    "from re import A\n",
    "c = 477\n",
    "def list_in(a, b):\n",
    "  return any(map(lambda x: b[x:x + len(a)] == a, range(len(b) - len(a) + 1)))\n",
    "\n",
    "encoded_answer = tokenizer( answer_matrix[c]['text'],  truncation=True)\n",
    "a = len(encoded_answer['input_ids'][0])\n",
    "b = encoded_answer['input_ids'][0][1:a-1]\n",
    "\n",
    "print(\"encoded_answer\", encoded_answer['input_ids'][0])\n",
    "print(\"answre\", b)\n",
    "\n",
    "text = tokenizer.convert_ids_to_tokens(encoded_train['input_ids'][c])\n",
    "answer = tokenizer.convert_ids_to_tokens(encoded_answer['input_ids'][0])\n",
    "print(\"text\", text)\n",
    "print(\"anser\", answer)\n",
    "def get_index(word, liste): \n",
    "  for i, word_list in enumerate(liste):\n",
    "    if word==word_list: \n",
    "      return i\n",
    "\n",
    "def get_bornes ( input_answer, input_context): \n",
    "  \"\"\" imput context is the matrix of the embedded context answer is the reel sentence \"\"\"\n",
    "  context =  tokenizer.convert_ids_to_tokens(input_context)\n",
    "  encoded_answer = tokenizer(input_answer ,  truncation=True)\n",
    "  answer = tokenizer.convert_ids_to_tokens(encoded_answer['input_ids'][0])\n",
    "  word_start = answer[1]\n",
    "  word_end = answer[-2]\n",
    "  idx_start = get_index(word_start,context )\n",
    "  if idx_start ==None: \n",
    "    return (1,2)\n",
    "  if (len(b)==1): \n",
    "    #print(\"indx_start\", idx_start)\n",
    "    return (idx_start,idx_start+1)\n",
    "\n",
    "  idx_end   = get_index(word_end, context)\n",
    "  #print(idx_end)\n",
    "  if idx_end < idx_start: \n",
    "      idx_end = idx_start +get_index(word_end,context[idx_start:] )+1\n",
    "      #print(\"index\", (idx_start, idx_end))\n",
    "      return (idx_start, idx_end)\n",
    "  else : \n",
    "    #print(\"index\", (idx_start, idx_end))\n",
    "    return (idx_start, idx_end)\n",
    "print (\"answer\", answer_matrix[c]['text'])\n",
    "if (len(encoded_answer['input_ids'][0])!=3):\n",
    "  ind1, ind2 = get_bornes(answer_matrix[c]['text'],[c] )\n",
    "  #print(text[ind1:ind2])\n",
    "if (len(encoded_answer['input_ids'][0])==3):\n",
    "  ind1 , id2= get_bornes(answer_matrix[c]['text'], encoded_train['input_ids'][c] )\n",
    "  #print(text[ind1:id2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW4HlqptZTAh",
    "outputId": "8f6cdd44-96ff-4c5b-99d7-620c7ed422d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000it [00:15, 1913.26it/s]\n",
      "10570it [00:08, 1209.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "def add_start_end_pos (encoded_data , answers): \n",
    "  contexts = encoded_data['input_ids']\n",
    "  end_pos= []\n",
    "  start_pos = []\n",
    "  for index, answer in tqdm(enumerate (answers)): \n",
    "    answ       = answer['text']\n",
    "    context    = contexts[index]\n",
    "    #print(answ, index)\n",
    "    start, end = get_bornes ( answ, context)\n",
    "    \n",
    "    start_pos.append(start)\n",
    "    end_pos.append(end)\n",
    " \n",
    "  encoded_data.update(\n",
    "      {'start_positions' : start_pos, \n",
    "       'end_positions': end_pos\n",
    "       }\n",
    "  )\n",
    "\n",
    "add_start_end_pos(encoded_train, answer_matrix)\n",
    "add_start_end_pos(encoded_val, answer_matrix_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHeP0QSc6l5n"
   },
   "source": [
    "## Model Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kav-0beMdBup"
   },
   "outputs": [],
   "source": [
    "data_train = Dataset(encoded_train)\n",
    "data_val   = Dataset(encoded_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "8016369f04d94dd38774a56833c8679a",
      "9898b387847641ce81a180b5abb8f937",
      "ed937cd2a8cd4c37881a19285c78d78e",
      "15f63fac24a64429ac78e447800998a1",
      "e2f6a1b99d494104b6a8aaefaa834b6d",
      "b9d85fd1154242d683fa4c4f8d442f61",
      "9eeb4d82161c4d82a04ce0433a4289dc",
      "a46de8a958af4d8488256d7b522dfe5d",
      "ebab440b46cd4e4b89568521db24284d",
      "5f00b3067ced4efe9e116a6b567a8cfd",
      "d86aa849c4da479ba41be23dec5a0372"
     ]
    },
    "id": "_ayS3hG8giAF",
    "outputId": "e4626560-b822-4f72-98ca-e3e8230785e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8016369f04d94dd38774a56833c8679a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-cased\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ1rICv36vb8"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZGMwo-Ne6SH",
    "outputId": "345140c1-4186-4831-ffc4-b8acc3717bb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#### Fine tuning \n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "from transformers import AdamW\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WwW4GmwugRA",
    "outputId": "a5f562ef-a284-4724-c311-79f5207d44bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  7 23:34:59 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    25W /  70W |   1854MiB / 15109MiB |     15%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_e3q-kgj_h0"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader( data_train ,batch_size= 10, shuffle= True)\n",
    "val_loader   = DataLoader( data_val   ,batch_size= 10, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6kW7YJtyo0O"
   },
   "outputs": [],
   "source": [
    "\"\"\" from https://debuggercafe.com/saving-and-loading-the-best-model-in-pytorch/ \"\"\"\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's \n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, path, best_valid_loss=float('inf')\n",
    "    ):\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.path = path \n",
    "        \n",
    "    def __call__(\n",
    "        self, current_valid_loss, \n",
    "        epoch, model, optimizer\n",
    "    ):\n",
    "        \n",
    "        if current_valid_loss < self.best_valid_loss:\n",
    "            self.best_valid_loss = current_valid_loss\n",
    "            #print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
    "            #print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
    "            #torch.save(model.state_dict(), '/content/gdrive/MyDrive/model_epoch200_tres.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': current_valid_loss,\n",
    "                }, self.path)\n",
    "# save on collab\n",
    "#torch.save(model.state_dict(), '/content/gdrive/MyDrive/model_epoch200_tres.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFVkGAKsyxBh",
    "outputId": "ffbbf21c-1911-434f-d7f3-7bf096fc5a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')    \n",
    "#saver1         = SaveBestModel('/content/gdrive/MyDrive/model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-O0s9HKYtDFC",
    "outputId": "4399d0ef-18b5-4877-eaf0-106c32ad9d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 3000/3000 [46:18<00:00,  1.08it/s, loss=1.27]\n",
      "Epoch 1: 100%|██████████| 3000/3000 [46:22<00:00,  1.08it/s, loss=0.817]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 2 \n",
    "\n",
    "for epoch in range (epochs):\n",
    "  loop = tqdm(train_loader)\n",
    "  for batch in loop:   \n",
    "    optim.zero_grad()\n",
    "    input_ids   = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_position  = batch['start_positions'].to(device)\n",
    "    end_position    = batch['end_positions'].to(device)\n",
    "\n",
    "    outputs = model(input_ids, attention_mask = attention_mask,  \n",
    "                     start_positions = start_position,\n",
    "                     end_positions =end_position  )\n",
    "    \n",
    "    loss = outputs[0]\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    #saver1.__call__(\n",
    "    #    loss, \n",
    "    #    epoch,\n",
    "    #    model, \n",
    "    #    optim\n",
    "    #    )\n",
    "\n",
    "    loop.set_description(f'Epoch {epoch}')\n",
    "    loop.set_postfix(loss = loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-NZBqpmiBIB",
    "outputId": "7e67f5a8-396c-412c-d52d-a2aa98db9673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/gdrive/MyDrive/model/bert-custom/tokenizer_config.json',\n",
       " '/content/gdrive/MyDrive/model/bert-custom/special_tokens_map.json',\n",
       " '/content/gdrive/MyDrive/model/bert-custom/vocab.txt',\n",
       " '/content/gdrive/MyDrive/model/bert-custom/added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/content/gdrive/MyDrive/model/bert-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g7r-BmggWp5"
   },
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wlRqW21FiYGU",
    "outputId": "42e6147b-5e40-4bd4-ba7d-386de98e2ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIKYZsKliaEa",
    "outputId": "c5900865-b5c8-4cfc-db67-c2a90ca1333b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1057 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/1057 [1:07:00<?, ?it/s]\n",
      "\n",
      "\n",
      "  0%|          | 1/1057 [00:00<06:02,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/1057 [00:00<05:31,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/1057 [00:00<05:22,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/1057 [00:01<05:18,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/1057 [00:01<05:16,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6/1057 [00:01<05:13,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 7/1057 [00:02<05:13,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 8/1057 [00:02<05:13,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 9/1057 [00:02<05:11,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 10/1057 [00:03<05:10,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 11/1057 [00:03<05:10,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 12/1057 [00:03<05:09,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 13/1057 [00:03<05:09,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 14/1057 [00:04<05:08,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 15/1057 [00:04<05:09,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 16/1057 [00:04<05:08,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 17/1057 [00:05<05:08,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 18/1057 [00:05<05:09,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 19/1057 [00:05<05:08,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 20/1057 [00:05<05:08,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 21/1057 [00:06<05:08,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 22/1057 [00:06<05:07,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 23/1057 [00:06<05:08,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 24/1057 [00:07<05:08,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 25/1057 [00:07<05:08,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 26/1057 [00:07<05:07,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 27/1057 [00:08<05:07,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 28/1057 [00:08<05:06,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 29/1057 [00:08<05:06,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 30/1057 [00:08<05:06,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 31/1057 [00:09<05:04,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 32/1057 [00:09<05:05,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 33/1057 [00:09<05:05,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 34/1057 [00:10<05:05,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 35/1057 [00:10<05:05,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 36/1057 [00:10<05:04,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 37/1057 [00:11<05:04,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 38/1057 [00:11<05:05,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 39/1057 [00:11<05:04,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 40/1057 [00:11<05:04,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 41/1057 [00:12<05:05,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 42/1057 [00:12<05:05,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 43/1057 [00:12<05:04,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 44/1057 [00:13<05:05,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 45/1057 [00:13<05:05,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 46/1057 [00:13<05:04,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 47/1057 [00:14<05:03,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 48/1057 [00:14<05:03,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 49/1057 [00:14<05:03,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 50/1057 [00:14<05:04,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 51/1057 [00:15<05:04,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 52/1057 [00:15<05:03,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 53/1057 [00:15<05:04,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 54/1057 [00:16<05:03,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 55/1057 [00:16<05:02,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 56/1057 [00:16<05:01,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 57/1057 [00:17<05:01,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 58/1057 [00:17<05:01,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 59/1057 [00:17<05:02,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 60/1057 [00:17<05:02,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 61/1057 [00:18<05:01,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 62/1057 [00:18<05:01,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 63/1057 [00:18<05:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 64/1057 [00:19<05:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 65/1057 [00:19<05:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 66/1057 [00:19<05:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 67/1057 [00:20<05:00,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 68/1057 [00:20<05:00,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 69/1057 [00:20<05:00,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 70/1057 [00:21<05:00,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 71/1057 [00:21<04:59,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 72/1057 [00:21<04:59,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 73/1057 [00:21<04:59,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 74/1057 [00:22<04:58,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 75/1057 [00:22<04:56,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 76/1057 [00:22<04:56,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 77/1057 [00:23<04:57,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 78/1057 [00:23<04:56,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 79/1057 [00:23<04:55,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 80/1057 [00:24<04:54,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 81/1057 [00:24<04:54,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 82/1057 [00:24<04:55,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 83/1057 [00:24<04:55,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 84/1057 [00:25<04:55,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 85/1057 [00:25<04:54,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 86/1057 [00:25<04:55,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 87/1057 [00:26<04:55,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 88/1057 [00:26<04:54,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 89/1057 [00:26<04:53,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 90/1057 [00:27<04:53,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 91/1057 [00:27<04:52,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 92/1057 [00:27<04:53,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 93/1057 [00:28<04:54,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 94/1057 [00:28<04:53,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 95/1057 [00:28<04:52,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 96/1057 [00:28<04:52,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 97/1057 [00:29<04:51,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 98/1057 [00:29<04:51,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 99/1057 [00:29<04:52,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 100/1057 [00:30<04:52,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 101/1057 [00:30<04:51,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 102/1057 [00:30<04:49,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 103/1057 [00:31<04:49,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 104/1057 [00:31<04:49,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 105/1057 [00:31<04:49,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 106/1057 [00:31<04:49,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 107/1057 [00:32<04:48,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 108/1057 [00:32<04:48,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 109/1057 [00:32<04:48,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 110/1057 [00:33<04:49,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 111/1057 [00:33<04:48,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 112/1057 [00:33<04:49,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 113/1057 [00:34<04:48,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 114/1057 [00:34<04:47,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 115/1057 [00:34<04:46,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 116/1057 [00:35<04:46,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 117/1057 [00:35<04:46,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 118/1057 [00:35<04:46,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 119/1057 [00:35<04:45,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 120/1057 [00:36<04:47,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 121/1057 [00:36<04:47,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 122/1057 [00:36<04:47,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 123/1057 [00:37<04:46,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 124/1057 [00:37<04:46,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 125/1057 [00:37<04:45,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 126/1057 [00:38<04:46,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 127/1057 [00:38<04:45,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 128/1057 [00:38<04:45,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 129/1057 [00:39<04:45,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 130/1057 [00:39<04:42,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 131/1057 [00:39<04:43,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 132/1057 [00:39<04:43,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 133/1057 [00:40<04:43,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 134/1057 [00:40<04:42,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 135/1057 [00:40<04:42,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 136/1057 [00:41<04:42,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 137/1057 [00:41<04:42,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 138/1057 [00:41<04:42,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 139/1057 [00:42<04:41,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 140/1057 [00:42<04:40,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 141/1057 [00:42<04:40,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 142/1057 [00:42<04:40,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 143/1057 [00:43<04:40,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 144/1057 [00:43<04:40,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 145/1057 [00:43<04:40,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 146/1057 [00:44<04:39,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 147/1057 [00:44<04:40,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 148/1057 [00:44<04:41,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 149/1057 [00:45<04:40,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 150/1057 [00:45<04:39,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 151/1057 [00:45<04:39,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 152/1057 [00:46<04:39,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 153/1057 [00:46<04:39,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 154/1057 [00:46<04:38,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 155/1057 [00:47<04:38,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 156/1057 [00:47<04:38,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 157/1057 [00:47<04:37,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 158/1057 [00:47<04:37,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 159/1057 [00:48<04:36,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 160/1057 [00:48<04:35,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 161/1057 [00:48<04:34,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 162/1057 [00:49<04:35,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 163/1057 [00:49<04:35,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 164/1057 [00:49<04:34,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 165/1057 [00:50<04:35,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 166/1057 [00:50<04:35,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 167/1057 [00:50<04:33,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 168/1057 [00:51<04:33,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 169/1057 [00:51<04:34,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 170/1057 [00:51<04:34,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 171/1057 [00:51<04:33,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 172/1057 [00:52<04:34,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 173/1057 [00:52<04:33,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 174/1057 [00:52<04:33,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 175/1057 [00:53<04:32,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 176/1057 [00:53<04:32,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 177/1057 [00:53<04:32,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 178/1057 [00:54<04:31,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 179/1057 [00:54<04:31,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 180/1057 [00:54<04:32,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 181/1057 [00:55<04:31,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 182/1057 [00:55<04:30,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 183/1057 [00:55<04:29,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 184/1057 [00:55<04:29,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 185/1057 [00:56<04:30,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 186/1057 [00:56<04:30,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 187/1057 [00:56<04:29,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 188/1057 [00:57<04:29,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 189/1057 [00:57<04:28,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 190/1057 [00:57<04:27,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 191/1057 [00:58<04:28,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 192/1057 [00:58<04:28,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 193/1057 [00:58<04:27,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 194/1057 [00:59<04:26,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 195/1057 [00:59<04:27,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 196/1057 [00:59<04:27,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 197/1057 [00:59<04:27,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 198/1057 [01:00<04:27,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 199/1057 [01:00<04:26,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 200/1057 [01:00<04:25,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 201/1057 [01:01<04:24,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 202/1057 [01:01<04:26,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 203/1057 [01:01<04:25,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 204/1057 [01:02<04:24,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 205/1057 [01:02<04:25,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 206/1057 [01:02<04:25,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 207/1057 [01:03<04:25,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 208/1057 [01:03<04:25,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 209/1057 [01:03<04:24,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 210/1057 [01:04<04:24,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 211/1057 [01:04<04:23,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 212/1057 [01:04<04:23,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 213/1057 [01:04<04:23,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 214/1057 [01:05<04:23,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 215/1057 [01:05<04:23,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 216/1057 [01:05<04:23,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 217/1057 [01:06<04:22,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 218/1057 [01:06<04:22,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 219/1057 [01:06<04:22,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 220/1057 [01:07<04:22,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 221/1057 [01:07<04:21,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 222/1057 [01:07<04:21,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 223/1057 [01:08<04:21,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 224/1057 [01:08<04:20,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 225/1057 [01:08<04:20,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 226/1057 [01:09<04:19,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 227/1057 [01:09<04:20,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 228/1057 [01:09<04:20,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 229/1057 [01:09<04:19,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 230/1057 [01:10<04:20,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 231/1057 [01:10<04:19,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 232/1057 [01:10<04:19,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 233/1057 [01:11<04:19,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 234/1057 [01:11<04:19,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 235/1057 [01:11<04:18,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 236/1057 [01:12<04:18,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 237/1057 [01:12<04:18,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 238/1057 [01:12<04:18,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 239/1057 [01:13<04:17,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 240/1057 [01:13<04:17,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 241/1057 [01:13<04:16,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 242/1057 [01:14<04:14,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 243/1057 [01:14<04:15,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 244/1057 [01:14<04:13,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 245/1057 [01:15<04:14,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 246/1057 [01:15<04:15,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 247/1057 [01:15<04:15,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 248/1057 [01:15<04:15,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 249/1057 [01:16<04:14,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 250/1057 [01:16<04:15,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 251/1057 [01:16<04:14,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 252/1057 [01:17<04:14,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 253/1057 [01:17<04:14,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 254/1057 [01:17<04:14,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 255/1057 [01:18<04:14,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 256/1057 [01:18<04:14,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 257/1057 [01:18<04:13,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 258/1057 [01:19<04:13,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 259/1057 [01:19<04:12,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 260/1057 [01:19<04:12,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 261/1057 [01:20<04:13,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 262/1057 [01:20<04:12,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 263/1057 [01:20<04:11,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 264/1057 [01:21<04:11,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 265/1057 [01:21<04:10,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 266/1057 [01:21<04:10,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 267/1057 [01:22<04:11,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 268/1057 [01:22<04:13,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 269/1057 [01:22<04:13,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 270/1057 [01:22<04:13,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 271/1057 [01:23<04:11,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 272/1057 [01:23<04:10,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 273/1057 [01:23<04:11,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 274/1057 [01:24<04:08,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 275/1057 [01:24<04:08,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 276/1057 [01:24<04:09,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 277/1057 [01:25<04:08,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 278/1057 [01:25<04:07,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 279/1057 [01:25<04:07,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 280/1057 [01:26<04:05,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 281/1057 [01:26<04:06,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 282/1057 [01:26<04:07,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 283/1057 [01:27<04:06,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 284/1057 [01:27<04:05,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 285/1057 [01:27<04:05,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 286/1057 [01:28<04:05,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 287/1057 [01:28<04:04,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 288/1057 [01:28<04:03,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 289/1057 [01:29<04:03,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 290/1057 [01:29<04:03,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 291/1057 [01:29<04:02,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 292/1057 [01:29<04:03,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 293/1057 [01:30<04:02,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 294/1057 [01:30<04:03,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 295/1057 [01:30<04:03,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 296/1057 [01:31<04:03,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 297/1057 [01:31<04:03,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 298/1057 [01:31<04:03,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 299/1057 [01:32<04:02,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 300/1057 [01:32<04:03,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 301/1057 [01:32<04:03,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 302/1057 [01:33<04:02,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 303/1057 [01:33<04:01,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 304/1057 [01:33<04:01,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 305/1057 [01:34<04:01,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 306/1057 [01:34<04:01,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 307/1057 [01:34<04:00,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 308/1057 [01:35<03:59,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 309/1057 [01:35<03:59,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 310/1057 [01:35<04:00,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 311/1057 [01:36<03:59,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 312/1057 [01:36<03:59,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 313/1057 [01:36<04:00,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 314/1057 [01:37<03:59,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 315/1057 [01:37<03:59,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 316/1057 [01:37<04:00,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 317/1057 [01:38<03:59,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 318/1057 [01:38<03:59,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 319/1057 [01:38<03:58,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 320/1057 [01:38<03:57,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 321/1057 [01:39<03:58,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 322/1057 [01:39<03:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 323/1057 [01:39<03:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 324/1057 [01:40<03:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 325/1057 [01:40<03:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 326/1057 [01:40<03:56,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 327/1057 [01:41<03:56,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 328/1057 [01:41<03:55,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 329/1057 [01:41<03:55,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 330/1057 [01:42<03:55,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 331/1057 [01:42<03:54,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 332/1057 [01:42<03:54,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 333/1057 [01:43<03:53,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 334/1057 [01:43<03:53,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 335/1057 [01:43<03:54,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 336/1057 [01:44<03:54,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 337/1057 [01:44<03:53,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 338/1057 [01:44<03:53,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 339/1057 [01:45<03:53,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 340/1057 [01:45<03:52,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 341/1057 [01:45<03:52,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 342/1057 [01:46<03:53,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 343/1057 [01:46<03:52,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 344/1057 [01:46<03:52,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 345/1057 [01:47<03:52,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 346/1057 [01:47<03:51,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 347/1057 [01:47<03:51,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 348/1057 [01:48<03:51,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 349/1057 [01:48<03:51,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 350/1057 [01:48<03:51,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 351/1057 [01:49<03:51,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 352/1057 [01:49<03:52,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 353/1057 [01:49<03:53,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 354/1057 [01:50<03:53,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 355/1057 [01:50<03:52,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 356/1057 [01:50<03:49,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 357/1057 [01:51<03:50,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 358/1057 [01:51<03:51,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 359/1057 [01:51<03:48,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 360/1057 [01:52<03:49,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 361/1057 [01:52<03:47,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 362/1057 [01:52<03:46,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 363/1057 [01:53<03:47,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 364/1057 [01:53<03:49,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 365/1057 [01:53<03:51,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 366/1057 [01:54<03:50,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 367/1057 [01:54<03:49,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 368/1057 [01:54<03:46,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 369/1057 [01:54<03:45,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 370/1057 [01:55<03:46,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 371/1057 [01:55<03:47,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 372/1057 [01:55<03:45,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 373/1057 [01:56<03:47,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 374/1057 [01:56<03:45,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 375/1057 [01:56<03:45,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 376/1057 [01:57<03:46,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 377/1057 [01:57<03:43,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 378/1057 [01:57<03:45,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 379/1057 [01:58<03:45,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 380/1057 [01:58<03:45,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 381/1057 [01:58<03:46,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 382/1057 [01:59<03:44,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 383/1057 [01:59<03:42,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 384/1057 [01:59<03:41,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 385/1057 [02:00<03:40,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 386/1057 [02:00<03:38,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 387/1057 [02:00<03:38,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 388/1057 [02:01<03:37,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 389/1057 [02:01<03:36,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 390/1057 [02:01<03:36,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 391/1057 [02:02<03:36,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 392/1057 [02:02<03:36,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 393/1057 [02:02<03:36,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 394/1057 [02:03<03:38,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 395/1057 [02:03<03:40,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 396/1057 [02:03<03:43,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 397/1057 [02:04<03:42,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 398/1057 [02:04<03:41,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 399/1057 [02:04<03:39,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 400/1057 [02:05<03:38,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 401/1057 [02:05<03:37,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 402/1057 [02:05<03:36,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 403/1057 [02:06<03:36,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 404/1057 [02:06<03:34,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 405/1057 [02:06<03:33,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 406/1057 [02:07<03:33,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 407/1057 [02:07<03:33,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 408/1057 [02:07<03:33,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 409/1057 [02:08<03:32,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 410/1057 [02:08<03:31,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 411/1057 [02:08<03:30,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 412/1057 [02:09<03:31,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 413/1057 [02:09<03:30,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 414/1057 [02:09<03:30,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 415/1057 [02:10<03:29,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 416/1057 [02:10<03:30,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 417/1057 [02:10<03:31,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 418/1057 [02:11<03:31,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 419/1057 [02:11<03:33,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 420/1057 [02:11<03:34,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 421/1057 [02:12<03:32,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 422/1057 [02:12<03:33,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 423/1057 [02:12<03:31,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 424/1057 [02:13<03:30,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 425/1057 [02:13<03:30,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 426/1057 [02:13<03:30,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 427/1057 [02:14<03:28,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 428/1057 [02:14<03:28,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 429/1057 [02:14<03:28,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 430/1057 [02:15<03:26,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 431/1057 [02:15<03:26,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 432/1057 [02:15<03:26,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 433/1057 [02:16<03:24,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 434/1057 [02:16<03:24,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 435/1057 [02:16<03:24,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 436/1057 [02:17<03:24,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 437/1057 [02:17<03:23,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 438/1057 [02:17<03:23,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 439/1057 [02:18<03:22,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 440/1057 [02:18<03:23,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 441/1057 [02:18<03:24,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 442/1057 [02:19<03:23,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 443/1057 [02:19<03:22,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 444/1057 [02:19<03:22,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 445/1057 [02:20<03:22,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 446/1057 [02:20<03:22,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 447/1057 [02:20<03:22,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 448/1057 [02:21<03:21,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 449/1057 [02:21<03:21,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 450/1057 [02:21<03:22,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 451/1057 [02:22<03:23,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 452/1057 [02:22<03:23,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 453/1057 [02:22<03:23,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 454/1057 [02:23<03:24,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 455/1057 [02:23<03:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 456/1057 [02:23<03:22,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 457/1057 [02:24<03:23,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 458/1057 [02:24<03:21,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 459/1057 [02:24<03:19,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 460/1057 [02:25<03:20,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 461/1057 [02:25<03:19,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 462/1057 [02:25<03:17,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 463/1057 [02:26<03:17,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 464/1057 [02:26<03:17,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 465/1057 [02:26<03:17,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 466/1057 [02:27<03:19,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 467/1057 [02:27<03:19,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 468/1057 [02:27<03:18,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 469/1057 [02:28<03:18,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 470/1057 [02:28<03:18,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 471/1057 [02:28<03:17,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 472/1057 [02:29<03:16,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 473/1057 [02:29<03:16,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 474/1057 [02:29<03:15,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 475/1057 [02:30<03:13,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 476/1057 [02:30<03:13,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 477/1057 [02:30<03:13,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 478/1057 [02:31<03:13,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 479/1057 [02:31<03:12,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 480/1057 [02:31<03:12,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 481/1057 [02:32<03:11,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 482/1057 [02:32<03:11,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 483/1057 [02:32<03:11,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 484/1057 [02:33<03:11,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 485/1057 [02:33<03:10,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 486/1057 [02:33<03:10,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 487/1057 [02:34<03:10,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 488/1057 [02:34<03:08,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 489/1057 [02:34<03:07,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 490/1057 [02:35<03:06,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 491/1057 [02:35<03:05,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 492/1057 [02:35<03:05,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 493/1057 [02:36<03:06,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 494/1057 [02:36<03:05,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 495/1057 [02:36<03:04,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 496/1057 [02:37<03:05,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 497/1057 [02:37<03:04,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 498/1057 [02:37<03:03,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 499/1057 [02:38<03:03,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 500/1057 [02:38<03:02,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 501/1057 [02:38<03:02,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 502/1057 [02:39<03:03,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 503/1057 [02:39<03:02,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 504/1057 [02:39<03:01,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 505/1057 [02:40<03:01,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 506/1057 [02:40<03:01,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 507/1057 [02:40<03:00,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 508/1057 [02:41<03:00,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 509/1057 [02:41<03:00,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 510/1057 [02:41<03:00,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 511/1057 [02:42<02:59,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 512/1057 [02:42<02:59,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 513/1057 [02:42<02:58,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 514/1057 [02:43<02:58,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 515/1057 [02:43<02:58,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 516/1057 [02:43<02:57,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 517/1057 [02:44<02:57,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 518/1057 [02:44<02:57,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 519/1057 [02:44<02:57,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 520/1057 [02:45<02:57,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 521/1057 [02:45<02:56,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 522/1057 [02:45<02:56,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 523/1057 [02:46<02:56,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 524/1057 [02:46<02:56,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 525/1057 [02:46<02:55,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 526/1057 [02:46<02:55,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 527/1057 [02:47<02:55,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 528/1057 [02:47<02:54,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 529/1057 [02:47<02:53,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 530/1057 [02:48<02:53,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 531/1057 [02:48<02:53,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 532/1057 [02:48<02:53,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 533/1057 [02:49<02:53,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 534/1057 [02:49<02:53,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 535/1057 [02:49<02:52,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 536/1057 [02:50<02:53,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 537/1057 [02:50<02:51,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 538/1057 [02:50<02:51,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 539/1057 [02:51<02:51,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 540/1057 [02:51<02:51,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 541/1057 [02:51<02:50,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 542/1057 [02:52<02:51,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 543/1057 [02:52<02:50,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 544/1057 [02:52<02:49,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 545/1057 [02:53<02:49,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 546/1057 [02:53<02:49,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 547/1057 [02:53<02:48,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 548/1057 [02:54<02:48,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 549/1057 [02:54<02:48,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 550/1057 [02:54<02:48,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 551/1057 [02:55<02:47,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 552/1057 [02:55<02:47,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 553/1057 [02:55<02:47,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 554/1057 [02:56<02:46,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 555/1057 [02:56<02:46,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 556/1057 [02:56<02:46,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 557/1057 [02:57<02:46,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 558/1057 [02:57<02:46,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 559/1057 [02:57<02:45,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 560/1057 [02:58<02:45,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 561/1057 [02:58<02:44,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 562/1057 [02:58<02:44,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 563/1057 [02:59<02:44,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 564/1057 [02:59<02:43,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 565/1057 [02:59<02:43,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 566/1057 [03:00<02:43,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 567/1057 [03:00<02:42,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 568/1057 [03:00<02:42,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 569/1057 [03:01<02:42,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 570/1057 [03:01<02:41,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 571/1057 [03:01<02:40,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 572/1057 [03:02<02:41,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 573/1057 [03:02<02:40,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 574/1057 [03:02<02:39,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 575/1057 [03:03<02:40,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 576/1057 [03:03<02:39,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 577/1057 [03:03<02:40,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 578/1057 [03:04<02:39,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 579/1057 [03:04<02:38,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 580/1057 [03:04<02:38,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 581/1057 [03:05<02:38,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 582/1057 [03:05<02:37,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 583/1057 [03:05<02:37,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 584/1057 [03:06<02:36,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 585/1057 [03:06<02:36,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 586/1057 [03:06<02:37,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 587/1057 [03:07<02:36,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 588/1057 [03:07<02:36,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 589/1057 [03:07<02:36,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 590/1057 [03:08<02:36,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 591/1057 [03:08<02:35,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 592/1057 [03:08<02:34,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 593/1057 [03:09<02:35,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 594/1057 [03:09<02:34,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 595/1057 [03:09<02:34,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 596/1057 [03:10<02:34,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 597/1057 [03:10<02:33,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 598/1057 [03:10<02:32,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 599/1057 [03:11<02:32,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 600/1057 [03:11<02:31,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 601/1057 [03:11<02:30,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 602/1057 [03:12<02:30,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 603/1057 [03:12<02:30,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 604/1057 [03:12<02:29,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 605/1057 [03:13<02:29,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 606/1057 [03:13<02:30,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 607/1057 [03:13<02:29,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 608/1057 [03:14<02:29,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 609/1057 [03:14<02:28,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 610/1057 [03:14<02:28,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 611/1057 [03:15<02:28,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 612/1057 [03:15<02:27,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 613/1057 [03:15<02:27,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 614/1057 [03:16<02:27,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 615/1057 [03:16<02:27,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 616/1057 [03:16<02:27,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 617/1057 [03:17<02:26,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 618/1057 [03:17<02:26,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 619/1057 [03:17<02:25,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 620/1057 [03:18<02:24,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 621/1057 [03:18<02:24,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 622/1057 [03:18<02:24,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 623/1057 [03:19<02:24,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 624/1057 [03:19<02:23,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 625/1057 [03:19<02:23,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 626/1057 [03:20<02:22,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 627/1057 [03:20<02:22,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 628/1057 [03:20<02:22,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 629/1057 [03:21<02:21,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 630/1057 [03:21<02:21,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 631/1057 [03:21<02:21,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 632/1057 [03:22<02:20,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 633/1057 [03:22<02:19,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 634/1057 [03:22<02:20,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 635/1057 [03:23<02:20,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 636/1057 [03:23<02:20,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 637/1057 [03:23<02:19,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 638/1057 [03:24<02:19,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 639/1057 [03:24<02:18,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 640/1057 [03:24<02:18,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 641/1057 [03:25<02:18,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 642/1057 [03:25<02:18,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 643/1057 [03:25<02:18,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 644/1057 [03:26<02:18,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 645/1057 [03:26<02:18,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 646/1057 [03:26<02:17,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 647/1057 [03:27<02:18,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 648/1057 [03:27<02:17,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 649/1057 [03:27<02:17,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 650/1057 [03:28<02:16,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 651/1057 [03:28<02:16,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 652/1057 [03:28<02:16,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 653/1057 [03:29<02:15,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 654/1057 [03:29<02:15,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 655/1057 [03:29<02:14,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 656/1057 [03:30<02:14,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 657/1057 [03:30<02:13,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 658/1057 [03:30<02:13,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 659/1057 [03:31<02:13,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 660/1057 [03:31<02:13,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 661/1057 [03:31<02:12,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 662/1057 [03:32<02:12,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 663/1057 [03:32<02:12,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 664/1057 [03:32<02:11,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 665/1057 [03:33<02:11,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 666/1057 [03:33<02:11,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 667/1057 [03:33<02:11,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 668/1057 [03:34<02:11,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 669/1057 [03:34<02:10,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 670/1057 [03:34<02:10,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 671/1057 [03:35<02:09,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 672/1057 [03:35<02:08,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 673/1057 [03:35<02:08,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 674/1057 [03:36<02:08,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 675/1057 [03:36<02:07,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 676/1057 [03:36<02:07,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 677/1057 [03:37<02:07,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 678/1057 [03:37<02:07,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 679/1057 [03:37<02:06,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 680/1057 [03:38<02:06,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 681/1057 [03:38<02:06,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 682/1057 [03:38<02:05,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 683/1057 [03:39<02:06,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 684/1057 [03:39<02:05,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 685/1057 [03:39<02:05,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 686/1057 [03:40<02:04,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 687/1057 [03:40<02:04,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 688/1057 [03:40<02:04,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 689/1057 [03:41<02:04,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 690/1057 [03:41<02:03,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 691/1057 [03:41<02:02,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 692/1057 [03:42<02:02,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 693/1057 [03:42<02:02,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 694/1057 [03:42<02:02,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 695/1057 [03:43<02:02,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 696/1057 [03:43<02:01,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 697/1057 [03:44<02:00,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 698/1057 [03:44<02:01,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 699/1057 [03:44<02:00,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 700/1057 [03:45<01:59,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 701/1057 [03:45<01:59,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 702/1057 [03:45<01:59,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 703/1057 [03:46<01:59,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 704/1057 [03:46<01:58,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 705/1057 [03:46<01:58,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 706/1057 [03:47<01:57,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 707/1057 [03:47<01:57,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 708/1057 [03:47<01:57,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 709/1057 [03:48<01:56,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 710/1057 [03:48<01:57,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 711/1057 [03:48<01:56,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 712/1057 [03:49<01:56,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 713/1057 [03:49<01:55,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 714/1057 [03:49<01:55,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 715/1057 [03:50<01:54,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 716/1057 [03:50<01:54,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 717/1057 [03:50<01:53,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 718/1057 [03:51<01:53,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 719/1057 [03:51<01:53,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 720/1057 [03:51<01:53,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 721/1057 [03:52<01:52,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 722/1057 [03:52<01:52,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 723/1057 [03:52<01:52,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 724/1057 [03:53<01:51,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 725/1057 [03:53<01:51,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 726/1057 [03:53<01:51,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 727/1057 [03:54<01:50,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 728/1057 [03:54<01:50,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 729/1057 [03:54<01:51,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 730/1057 [03:55<01:50,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 731/1057 [03:55<01:49,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 732/1057 [03:55<01:49,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 733/1057 [03:56<01:49,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 734/1057 [03:56<01:49,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 735/1057 [03:56<01:48,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 736/1057 [03:57<01:48,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 737/1057 [03:57<01:47,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 738/1057 [03:57<01:48,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 739/1057 [03:58<01:47,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 740/1057 [03:58<01:46,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 741/1057 [03:58<01:46,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 742/1057 [03:59<01:46,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 743/1057 [03:59<01:45,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 744/1057 [03:59<01:45,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 745/1057 [04:00<01:44,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 746/1057 [04:00<01:44,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 747/1057 [04:00<01:44,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 748/1057 [04:01<01:43,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 749/1057 [04:01<01:43,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 750/1057 [04:01<01:43,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 751/1057 [04:02<01:43,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 752/1057 [04:02<01:42,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 753/1057 [04:02<01:42,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 754/1057 [04:03<01:42,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 755/1057 [04:03<01:41,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 756/1057 [04:03<01:41,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 757/1057 [04:04<01:42,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 758/1057 [04:04<01:41,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 759/1057 [04:04<01:41,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 760/1057 [04:05<01:41,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 761/1057 [04:05<01:40,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 762/1057 [04:05<01:40,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 763/1057 [04:06<01:40,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 764/1057 [04:06<01:40,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 765/1057 [04:06<01:39,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 766/1057 [04:07<01:39,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 767/1057 [04:07<01:38,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 768/1057 [04:07<01:38,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 769/1057 [04:08<01:38,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 770/1057 [04:08<01:37,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 771/1057 [04:08<01:36,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 772/1057 [04:09<01:36,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 773/1057 [04:09<01:36,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 774/1057 [04:10<01:35,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 775/1057 [04:10<01:36,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 776/1057 [04:10<01:36,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 777/1057 [04:11<01:36,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 778/1057 [04:11<01:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 779/1057 [04:11<01:35,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 780/1057 [04:12<01:35,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 781/1057 [04:12<01:34,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 782/1057 [04:12<01:33,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 783/1057 [04:13<01:33,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 784/1057 [04:13<01:32,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 785/1057 [04:13<01:32,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 786/1057 [04:14<01:32,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 787/1057 [04:14<01:32,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 788/1057 [04:14<01:31,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 789/1057 [04:15<01:30,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 790/1057 [04:15<01:30,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 791/1057 [04:15<01:30,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 792/1057 [04:16<01:29,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 793/1057 [04:16<01:29,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 794/1057 [04:16<01:29,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 795/1057 [04:17<01:28,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 796/1057 [04:17<01:28,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 797/1057 [04:17<01:28,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 798/1057 [04:18<01:28,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 799/1057 [04:18<01:27,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 800/1057 [04:18<01:26,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 801/1057 [04:19<01:27,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 802/1057 [04:19<01:26,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 803/1057 [04:19<01:26,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 804/1057 [04:20<01:26,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 805/1057 [04:20<01:25,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 806/1057 [04:20<01:25,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 807/1057 [04:21<01:25,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 808/1057 [04:21<01:24,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 809/1057 [04:21<01:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 810/1057 [04:22<01:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 811/1057 [04:22<01:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 812/1057 [04:22<01:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 813/1057 [04:23<01:22,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 814/1057 [04:23<01:22,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 815/1057 [04:23<01:22,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 816/1057 [04:24<01:22,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 817/1057 [04:24<01:21,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 818/1057 [04:25<01:21,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 819/1057 [04:25<01:21,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 820/1057 [04:25<01:21,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 821/1057 [04:26<01:20,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 822/1057 [04:26<01:20,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 823/1057 [04:26<01:20,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 824/1057 [04:27<01:19,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 825/1057 [04:27<01:19,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 826/1057 [04:27<01:18,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 827/1057 [04:28<01:18,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 828/1057 [04:28<01:18,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 829/1057 [04:28<01:17,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 830/1057 [04:29<01:17,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 831/1057 [04:29<01:17,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 832/1057 [04:29<01:16,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 833/1057 [04:30<01:16,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 834/1057 [04:30<01:15,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 835/1057 [04:30<01:15,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 836/1057 [04:31<01:14,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 837/1057 [04:31<01:14,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 838/1057 [04:31<01:14,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 839/1057 [04:32<01:14,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 840/1057 [04:32<01:13,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 841/1057 [04:32<01:13,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 842/1057 [04:33<01:13,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 843/1057 [04:33<01:12,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 844/1057 [04:33<01:12,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 845/1057 [04:34<01:12,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 846/1057 [04:34<01:11,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 847/1057 [04:34<01:11,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 848/1057 [04:35<01:11,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 849/1057 [04:35<01:10,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 850/1057 [04:35<01:10,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 851/1057 [04:36<01:10,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 852/1057 [04:36<01:09,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 853/1057 [04:36<01:09,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 854/1057 [04:37<01:08,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 855/1057 [04:37<01:08,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 856/1057 [04:37<01:07,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 857/1057 [04:38<01:07,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 858/1057 [04:38<01:07,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 859/1057 [04:38<01:07,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 860/1057 [04:39<01:06,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 861/1057 [04:39<01:06,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 862/1057 [04:39<01:06,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 863/1057 [04:40<01:06,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 864/1057 [04:40<01:05,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 865/1057 [04:41<01:05,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 866/1057 [04:41<01:05,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 867/1057 [04:41<01:05,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 868/1057 [04:42<01:04,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 869/1057 [04:42<01:04,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 870/1057 [04:42<01:04,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 871/1057 [04:43<01:03,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 872/1057 [04:43<01:03,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 873/1057 [04:43<01:02,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 874/1057 [04:44<01:02,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 875/1057 [04:44<01:01,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 876/1057 [04:44<01:01,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 877/1057 [04:45<01:01,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 878/1057 [04:45<01:01,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 879/1057 [04:45<01:00,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 880/1057 [04:46<01:00,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 881/1057 [04:46<01:00,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 882/1057 [04:46<00:59,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 883/1057 [04:47<00:59,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 884/1057 [04:47<00:59,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 885/1057 [04:47<00:58,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 886/1057 [04:48<00:58,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 887/1057 [04:48<00:57,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 888/1057 [04:48<00:57,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 889/1057 [04:49<00:57,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 890/1057 [04:49<00:57,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 891/1057 [04:49<00:56,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 892/1057 [04:50<00:56,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 893/1057 [04:50<00:56,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 894/1057 [04:50<00:55,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 895/1057 [04:51<00:55,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 896/1057 [04:51<00:55,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 897/1057 [04:51<00:54,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 898/1057 [04:52<00:54,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 899/1057 [04:52<00:53,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 900/1057 [04:52<00:53,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 901/1057 [04:53<00:53,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 902/1057 [04:53<00:53,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 903/1057 [04:53<00:52,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 904/1057 [04:54<00:52,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 905/1057 [04:54<00:52,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 906/1057 [04:55<00:51,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 907/1057 [04:55<00:51,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 908/1057 [04:55<00:50,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 909/1057 [04:56<00:50,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 910/1057 [04:56<00:50,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 911/1057 [04:56<00:49,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 912/1057 [04:57<00:49,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 913/1057 [04:57<00:49,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 914/1057 [04:57<00:48,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 915/1057 [04:58<00:48,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 916/1057 [04:58<00:47,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 917/1057 [04:58<00:47,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 918/1057 [04:59<00:47,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 919/1057 [04:59<00:46,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 920/1057 [04:59<00:46,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 921/1057 [05:00<00:46,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 922/1057 [05:00<00:46,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 923/1057 [05:00<00:45,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 924/1057 [05:01<00:45,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 925/1057 [05:01<00:45,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 926/1057 [05:01<00:44,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 927/1057 [05:02<00:44,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 928/1057 [05:02<00:43,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 929/1057 [05:02<00:43,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 930/1057 [05:03<00:43,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 931/1057 [05:03<00:43,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 932/1057 [05:03<00:42,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 933/1057 [05:04<00:42,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 934/1057 [05:04<00:42,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 935/1057 [05:04<00:42,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 936/1057 [05:05<00:42,  2.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 937/1057 [05:05<00:41,  2.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 938/1057 [05:05<00:41,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 939/1057 [05:06<00:40,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 940/1057 [05:06<00:40,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 941/1057 [05:07<00:39,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 942/1057 [05:07<00:39,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 943/1057 [05:07<00:39,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 944/1057 [05:08<00:38,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 945/1057 [05:08<00:38,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 946/1057 [05:08<00:38,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 947/1057 [05:09<00:37,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 948/1057 [05:09<00:37,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 949/1057 [05:09<00:37,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 950/1057 [05:10<00:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 951/1057 [05:10<00:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 952/1057 [05:10<00:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 953/1057 [05:11<00:35,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 954/1057 [05:11<00:35,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 955/1057 [05:11<00:35,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 956/1057 [05:12<00:34,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 957/1057 [05:12<00:34,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 958/1057 [05:12<00:33,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 959/1057 [05:13<00:33,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 960/1057 [05:13<00:33,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 961/1057 [05:13<00:32,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 962/1057 [05:14<00:32,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 963/1057 [05:14<00:31,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 964/1057 [05:14<00:31,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 965/1057 [05:15<00:31,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 966/1057 [05:15<00:30,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 967/1057 [05:15<00:30,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 968/1057 [05:16<00:30,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 969/1057 [05:16<00:30,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 970/1057 [05:16<00:29,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 971/1057 [05:17<00:29,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 972/1057 [05:17<00:29,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 973/1057 [05:17<00:28,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 974/1057 [05:18<00:28,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 975/1057 [05:18<00:28,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 976/1057 [05:18<00:27,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 977/1057 [05:19<00:27,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 978/1057 [05:19<00:26,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 979/1057 [05:20<00:26,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 980/1057 [05:20<00:26,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 981/1057 [05:20<00:25,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 982/1057 [05:21<00:25,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 983/1057 [05:21<00:25,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 984/1057 [05:21<00:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 985/1057 [05:22<00:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 986/1057 [05:22<00:24,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 987/1057 [05:22<00:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 988/1057 [05:23<00:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 989/1057 [05:23<00:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 990/1057 [05:23<00:22,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 991/1057 [05:24<00:22,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 992/1057 [05:24<00:22,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 993/1057 [05:24<00:21,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 994/1057 [05:25<00:21,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 995/1057 [05:25<00:21,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 996/1057 [05:25<00:21,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 997/1057 [05:26<00:20,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 998/1057 [05:26<00:20,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 999/1057 [05:26<00:19,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1000/1057 [05:27<00:19,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1001/1057 [05:27<00:19,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1002/1057 [05:27<00:18,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1003/1057 [05:28<00:18,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 1004/1057 [05:28<00:18,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1005/1057 [05:28<00:17,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1006/1057 [05:29<00:17,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1007/1057 [05:29<00:17,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1008/1057 [05:29<00:16,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1009/1057 [05:30<00:16,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1010/1057 [05:30<00:16,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1011/1057 [05:30<00:16,  2.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1012/1057 [05:31<00:15,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1013/1057 [05:31<00:15,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1014/1057 [05:32<00:14,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1015/1057 [05:32<00:14,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1016/1057 [05:32<00:14,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 1017/1057 [05:33<00:13,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 1018/1057 [05:33<00:13,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 1019/1057 [05:33<00:13,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 1020/1057 [05:34<00:12,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1021/1057 [05:34<00:12,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1022/1057 [05:34<00:12,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1023/1057 [05:35<00:11,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1024/1057 [05:35<00:11,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1025/1057 [05:35<00:11,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1026/1057 [05:36<00:10,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1027/1057 [05:36<00:10,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1028/1057 [05:36<00:09,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1029/1057 [05:37<00:09,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 1030/1057 [05:37<00:09,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1031/1057 [05:37<00:08,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1032/1057 [05:38<00:08,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1033/1057 [05:38<00:08,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1034/1057 [05:38<00:07,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1035/1057 [05:39<00:07,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1036/1057 [05:39<00:07,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1037/1057 [05:39<00:06,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1038/1057 [05:40<00:06,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1039/1057 [05:40<00:06,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1040/1057 [05:40<00:05,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 1041/1057 [05:41<00:05,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 1042/1057 [05:41<00:05,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 1043/1057 [05:41<00:04,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1044/1057 [05:42<00:04,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1045/1057 [05:42<00:04,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1046/1057 [05:42<00:03,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1047/1057 [05:43<00:03,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1048/1057 [05:43<00:03,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1049/1057 [05:44<00:02,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1050/1057 [05:44<00:02,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 1051/1057 [05:44<00:02,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1052/1057 [05:45<00:01,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1053/1057 [05:45<00:01,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1054/1057 [05:45<00:01,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1055/1057 [05:46<00:00,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 1056/1057 [05:46<00:00,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1057/1057 [05:46<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loop = tqdm(val_loader)\n",
    "acc_start=[]\n",
    "acc_end= []\n",
    "for batch in tqdm (val_loader): \n",
    "  with torch.no_grad():\n",
    "    input_ids   = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    start_true  = batch['start_positions'].to(device)\n",
    "    end_true    = batch['end_positions'].to(device)\n",
    "\n",
    "    outputs = model(input_ids, attention_mask = attention_mask)\n",
    "    \n",
    "    start_pred = torch.argmax(outputs['start_logits'], dim = 1)\n",
    "    end_pred   = torch.argmax(outputs['end_logits'], dim = 1)\n",
    "    \n",
    "    acc_start.append(((start_pred == start_true).sum()/len(start_pred)).item())\n",
    "    acc_end.append(((end_pred == end_true).sum()/len(start_pred)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEtm7lnKsEM3",
    "outputId": "67a9ae12-c3fd-4961-cb21-fb625a215b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Results of accuracy on the validation set==================\n",
      "accuracy for the start position :  0.6073793820268496\n",
      "accuracy for the end position   :  0.6028382284469839\n",
      "___________________________________\n",
      "accuracy for the all set   :  0.6051088052369168\n"
     ]
    }
   ],
   "source": [
    "print(\"======== Results of accuracy on the validation set==================\")\n",
    "print( \"accuracy for the start position : \" , sum(acc_start)/len(acc_start) ) \n",
    "print( \"accuracy for the end position   : \" , sum(acc_end)/len(acc_end) ) \n",
    "b = acc_start.copy()+acc_end\n",
    "print(\"__________________________________\")\n",
    "print( \"accuracy for the all set   : \" , sum(b)/len(b) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXHRuVW2xMHd"
   },
   "source": [
    "**==============================================================================================================**\n",
    "\n",
    "$$\\text{So with bert we get around 60 % of accuracy on the all positions}$$\n",
    "\n",
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGIYWZDUJXwa"
   },
   "source": [
    "> **Problem 3.2** *(2 points)* Try your own context/questions and find two failure cases. Explain why you think the model got them wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4va54HiFjp8"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_Hhf_S2wR8H",
    "outputId": "d795c897-4709-4560-b728-a92bd75b495d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "my_context = [\" I am a cat who lives in a flat between a bakery and a bank. My owner is a nice old lady, her name is Marry who has grey hair and glases. The neighbourg has a doc which I hate, the best fiend of the old lady has a rabbit which is my friend. \", \n",
    "              \" Korea is a country of Asia, located next to Japan\", \n",
    "              \"Dog are disgusting while Cats are beautiful. Cats are way better than all the Dogs. \"]\n",
    "my_question = [\"Who is the owner of the cat ? \", \n",
    "                \"Where is Korea? \", \n",
    "               \"Who is the best beteween Cats and Dogs ?  \"]\n",
    "\n",
    "encoded = tokenizer(my_context, my_question, truncation=True,  padding='max_length')\n",
    "model_path = '/content/gdrive/MyDrive/model/bert-custom'\n",
    "model_BERT = BertForQuestionAnswering.from_pretrained(model_path)\n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "my_data = Dataset(encoded)\n",
    "my_loader = DataLoader( my_data)\n",
    "start_pred=[]\n",
    "end_pred  =[]\n",
    "for batch in tqdm (my_loader): \n",
    "  with torch.no_grad():\n",
    "    input_ids      = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "\n",
    "    outputs = model_BERT(input_ids, attention_mask = attention_mask)\n",
    "    start_pred.append(torch.argmax(outputs['start_logits'], dim = 1))\n",
    "    end_pred.append(torch.argmax(outputs['end_logits'], dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKJlzr8Q2EX8",
    "outputId": "491fdf67-8c5b-4714-f3e1-565dc71d3730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 :  Who is the owner of the cat ? \n",
      "answer:  Mar ##ry\n",
      "Question 2 : Where is Korea? \n",
      "answer :  Asia ,\n",
      "Question 3 : Who is the best beteween Cats and Dogs ?  \n",
      "answer :  Dog are\n"
     ]
    }
   ],
   "source": [
    "answer1 = tokenizer.convert_ids_to_tokens(encoded['input_ids'][0][int(start_pred[0]):(int(end_pred[0])+1)])\n",
    "answer2 = tokenizer.convert_ids_to_tokens(encoded['input_ids'][1][int(start_pred[1]):(int(end_pred[1])+1)])\n",
    "answer3 = tokenizer.convert_ids_to_tokens(encoded['input_ids'][2][int(start_pred[2]):(int(end_pred[2])+1)])\n",
    "\n",
    "print(\"Question 1 : \", my_question[0])\n",
    "print(\"answer: \", \" \".join(answer1))\n",
    "print(\"Question 2 :\", my_question[1])\n",
    "print(\"answer : \", \" \".join(answer2))\n",
    "print(\"Question 3 :\", my_question[2])\n",
    "print(\"answer : \", \" \".join(answer3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF6z-6I6Jago"
   },
   "source": [
    "Here BERT Bert manadge to find the answer for the first and second question.\n",
    "For the question 3 BERT simply gets the oposite result, the answer was not dog but cats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYrslIhwKEJ_"
   },
   "source": [
    "## Truncation strategies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6UWvP_YJ-Gw"
   },
   "source": [
    "> **Problem 3.3** *(2 points)* Can we do better than truncating tokens if the input length is too long? Suggest (but do not code) a strategy for a problem like SQuAD when the input has an arbitrary length with a pretrained model like BERT that has a predefined input length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeKktwTix2tc"
   },
   "source": [
    "We can find to strategies the first one is to stick with truncature and the second one is to reduce the size of the texte without any truncature. \n",
    "\n",
    "\n",
    "\n",
    "1° - Truncature : \n",
    "This method would consist in reusing the tuncated part as anoter context. It appears like a subcontext. Like that we don't lost and aswer wich might be in the truncated part of the text. We can add truncation strategie to this method. One of the stratgie is to avoid as much as possible the [PAD] token by overlapping context one one another. Like in the following exemple : \n",
    "text(ex: 5, \"I have a brown cat\") longer than max_length(for ex:3), then instext of simply producing 2 subcontext with one with which is padded like a we go for b \n",
    "\n",
    "$$ \\text{a: [(\"I have a\"), (\"brown cat [pad]\")] becomes b:[(\"I have a\"), (\"have a brown\"), (\"a brown cat\")]} $$\n",
    "\n",
    "Like that we keep as mush information as possible in each context. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2° - Summarization : \n",
    "An unbiased summarization model is potentially able to extract important parts of the text regardless of their original position, resulting in a highly generalized shortening method. With this method we could shortened the the size of the imput to precisely Max_Bert_Size - 2 (cause we have to had the start and end token). The summarization   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-hD1L58jsG5"
   },
   "source": [
    "# 3. Machine Reading Comprehension with T5\n",
    "\n",
    "Here, you will instead formulate machine reading comprehension as a generation problem, which means the answer is generated on the decoder side given the inputs on the encoder side. There are several choices for pretrained language models but you will use T5 here, as you have been familiarized in Lab 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "EjXPAE3-tHty",
    "outputId": "34231011-7e47-48c0-ffb5-84198003c7d0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://www.youtube.com/watch?v=r6XY80Z9eSA'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"https://www.youtube.com/watch?v=r6XY80Z9eSA\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z2NYMefp6Sx"
   },
   "source": [
    "> **Problem 3.1** *(3 points)* Finetune `t5-small` model for `squad` question answering dataset and report the accuracy on the validation set. For convenience, ignore examples that have more than 256 tokens after tokenization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtMxV11iXn99"
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpZQOeVPqWip",
    "outputId": "39691977-ed94-4712-f13f-676f2ea34feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |████▏                           | 10 kB 29.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 20 kB 24.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 30 kB 12.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 40 kB 9.6 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 51 kB 4.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 61 kB 5.6 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 71 kB 6.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 78 kB 3.9 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "! pip install -q tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "om6J9hthrKD4"
   },
   "outputs": [],
   "source": [
    "! pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDLgVF9bsu45"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlCLG4q7WKBl",
    "outputId": "29c59fc3-6642-461a-f692-0bf99f9e77ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 680 kB 5.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 829 kB 57.7 MB/s \n",
      "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pytorch-lightning==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "1c0e7d8d4eab44649532132e8fbef185",
      "8bbb9df619ce43509589cd7996bf25a9",
      "2f7b5a3377cb4ffb88738ee1188d4b3c",
      "b89d583acf174b3aa7ef8201a6195e69",
      "0dae339ea5b046c0947c4d9b7a91843e",
      "8de9136e5fdc4ddda38fa223b7dfe41f",
      "b31736718a3a4189aafe3bca63ddf5be",
      "afcb28732f1942319a06825e944cf651",
      "31a16315960c415f8cd32e5d3439b18f",
      "e184eec8920a4da9aa71f89bf30eea14",
      "57a8c5ce35f643c6b25a74c88d8d4ab9"
     ]
    },
    "id": "LnfoJq58rZgI",
    "outputId": "53c4b482-107c-47d4-d67a-178ec4507fb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0e7d8d4eab44649532132e8fbef185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Imports\n",
    "from transformers import AdamW\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5TokenizerFast as T5Tokenizer\n",
    "\n",
    "import torch \n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "squad_dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktb-PmZpXjJN"
   },
   "source": [
    "# Dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HevcLpP-tEhr",
    "outputId": "71d94448-064f-4c33-85bc-cc39882d8024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Saint Bernadette Soubirous']\n",
      "question:  How much did Beyonce initially contribute to the foundation?\n",
      "answer :   {'text': ['$250,000'], 'answer_start': [190], 'answer_end': [191]}\n",
      "contex :   After Hurricane Katrina in 2005, Beyoncé and Rowland founded the Survivor Foundation to provide transitional housing for victims in the Houston area, to which Beyoncé contributed an initial $250,000. The foundation has since expanded to work with other charities in the city, and also provided relief following Hurricane Ike three years later.\n"
     ]
    }
   ],
   "source": [
    "### Dataset creation \n",
    "\n",
    "# training set \n",
    "contexts  = squad_dataset['train']['context']\n",
    "questions = squad_dataset['train']['question']\n",
    "answers   = squad_dataset['train']['answers']\n",
    "print(answers[0]['text'])\n",
    "\n",
    "# validation set \n",
    "contexts_v = squad_dataset['validation']['context']\n",
    "questions_v= squad_dataset['validation']['question']\n",
    "answers_v  = squad_dataset['validation']['answers']\n",
    "\n",
    "## Add the end index to the answers and correct the wrong start index : \n",
    "\n",
    "def start_end_index(contexts, answers): \n",
    "  \"\"\" Be carefull answers can be either a list of plosible elements or a list of one element \n",
    "      We add in the answer dictionnairy the start index and the endex index of the answer in \n",
    "      the context, the transformer requires it.  \"\"\"\n",
    "  # firstly we goes throught each of them : \n",
    "  for context, answer in zip (contexts, answers): \n",
    "    answer_text = answer['text']\n",
    "    answer_start= answer['answer_start'][0]\n",
    "    answer_end  = answer_start + len(answer_text)  # ideal end token if there is no mistakes in the start token\n",
    "    if len(context[answer_start:answer_end]) == len(answer_text): # every thing is fine\n",
    "      answer['answer_end']= [answer_end]\n",
    "    else:  \n",
    "      for index_shift in [1,2]:  # it is said that it is usually shif from one or two characters : \n",
    "        if context[answer_start-index_shift : answer_end - index_shift] == len(answer_text): # every thing is fine\n",
    "          answer['answer_start']= [answer_start-index_shift]\n",
    "          answer['answer_end']= [answer_end -index_shift]\n",
    "          print(answer)\n",
    "\n",
    "        elif context[answer_start + index_shift :answer_end + index_shift] == len(answer_text): # every thing is fine\n",
    "          answer['answer_start']= [answer_start+index_shift]\n",
    "          answer['answer_end']= [answer_end + index_shift]\n",
    "\n",
    "# Add of the end in the training and validation set \n",
    "start_end_index(contexts  , answers)\n",
    "start_end_index(contexts_v, answers_v)\n",
    "\n",
    "#Small test\n",
    "print(\"question: \", questions[1000])\n",
    "print(\"answer :  \", answers[1000])\n",
    "print(\"contex :  \" , contexts[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oQPwkyVvfsu",
    "outputId": "38383a6c-5f42-47de-d715-ff914926b29f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer :   dict_items([('text', ['$250,000']), ('answer_start', [190]), ('answer_end', [191])])\n"
     ]
    }
   ],
   "source": [
    "print(\"answer :  \", answers[1000].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wscP8e7rWgdj"
   },
   "source": [
    "As we ca see the dictionnairy with the answers now contains the strat index and the endex index of the aswer in the context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcL_cmHQtlXe"
   },
   "outputs": [],
   "source": [
    "# Made a clean panda dataset \n",
    "\n",
    "def datacontructor(questions, answers, contexts): \n",
    "  \"\"\" This methode creates a clean panda dataframe with all the info we will \n",
    "  feed to the Transformer dataframe\"\"\"\n",
    "  data = []\n",
    "  for question, context, answer in zip (questions, contexts, answers): \n",
    "    text         = answer[\"text\"][0] \n",
    "    answer_start = answer[\"answer_start\"]\n",
    "    answer_end   = answer[\"answer_end\"]\n",
    "    data.append({\n",
    "        \"question\" : question, \n",
    "        \"context\"  : context, \n",
    "        \"text\"          : text,\n",
    "        \"answer_start\"  : answer_start,\n",
    "        \"answer_end\"    : answer_end\n",
    "    })\n",
    "  return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBiuT3OWwRSg"
   },
   "outputs": [],
   "source": [
    "dataset = datacontructor(questions, answers, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvhNYHu-we0C",
    "outputId": "0f93b9f8-5af0-4268-ca2e-7e995378571d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  To whom did the Virgin Mary allegedly appear i...   \n",
      "1  What is in front of the Notre Dame Main Building?   \n",
      "2  The Basilica of the Sacred heart at Notre Dame...   \n",
      "3                  What is the Grotto at Notre Dame?   \n",
      "4  What sits on top of the Main Building at Notre...   \n",
      "5  When did the Scholastic Magazine of Notre dame...   \n",
      "6   How often is Notre Dame's the Juggler published?   \n",
      "7  What is the daily student paper at Notre Dame ...   \n",
      "8  How many student news papers are found at Notr...   \n",
      "9  In what year did the student paper Common Sens...   \n",
      "\n",
      "                                             context  \\\n",
      "0  Architecturally, the school has a Catholic cha...   \n",
      "1  Architecturally, the school has a Catholic cha...   \n",
      "2  Architecturally, the school has a Catholic cha...   \n",
      "3  Architecturally, the school has a Catholic cha...   \n",
      "4  Architecturally, the school has a Catholic cha...   \n",
      "5  As at most other universities, Notre Dame's st...   \n",
      "6  As at most other universities, Notre Dame's st...   \n",
      "7  As at most other universities, Notre Dame's st...   \n",
      "8  As at most other universities, Notre Dame's st...   \n",
      "9  As at most other universities, Notre Dame's st...   \n",
      "\n",
      "                                      text answer_start answer_end  \n",
      "0               Saint Bernadette Soubirous        [515]      [516]  \n",
      "1                a copper statue of Christ        [188]      [189]  \n",
      "2                        the Main Building        [279]      [280]  \n",
      "3  a Marian place of prayer and reflection        [381]      [382]  \n",
      "4       a golden statue of the Virgin Mary         [92]       [93]  \n",
      "5                           September 1876        [248]      [249]  \n",
      "6                                    twice        [441]      [442]  \n",
      "7                             The Observer        [598]      [599]  \n",
      "8                                    three        [126]      [127]  \n",
      "9                                     1987        [908]      [909]  \n"
     ]
    }
   ],
   "source": [
    "pprint(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6Hg_kKHwmam",
    "outputId": "55377ac0-9b1a-43c7-cb58-9e535220ad67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPluisbsXd5a"
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVmyr_nwXzbn"
   },
   "source": [
    "Import of the T5 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "8fdd2f684d76401eac5c6eddcc3aeca5",
      "05107c3bb3d64e89b1bc04fcd5634568",
      "2d94480937074562904cf04374f75963",
      "a50a15e2c12c4c77996cadde2cea6783",
      "d49cd045d560480788f6b944a51fd992",
      "a02fafb2aabc44df965b67da26a2ad0d",
      "d22a8daa094f474fb9cb677214bcd16e",
      "f37877ed50e84deba26a177aa0ad6b2b",
      "e6fb4bfb4816475497ca11d03087aa20",
      "07704fb767104911a99b87af341d317f",
      "cc840f86eec04151a5e02fb80bfc0b9d",
      "7410a3ce72b0419395f8f1e8471d5ecc",
      "8fea1ec5fd02460fa4a738fc5b180398",
      "36716f24b1f34f93904d11e0b7043451",
      "12e62a3bcde94140b16e8e37420b907c",
      "5f5b3249800745ab90c48d7ec2cda01f",
      "5ae82c3eb87c4c81a1daa34419590a5c",
      "6d3d3d4c3c79498e98a77b0a0cdc5df1",
      "6f11e0e838784079afdd0b0ca8c2757c",
      "a720c51460fa4362982c8c5e00de9f5c",
      "73d2f754a31640659e7aa4d45bb255e2",
      "9f5db1c3f5d84bf4a00f2acc5f24db8e",
      "593cd37ef15c41f9a69706ebd3e7441a",
      "4b7e7b0fa0d043ccb287b2f849df6d20",
      "ddcf6219e54b45a4855c8c6c2514c96f",
      "40b7f13935d14b1ca1feba12a61ff566",
      "5fbf5c449e804ef0b14d01a0350cf425",
      "273ef8651a9349e6ac45ae5a6e7b6955",
      "00429985e01b4defa60d016752c7ae79",
      "663d733e19f04acbaf15950016f9ae86",
      "082fefda297046da890a35d56a384db0",
      "779f8f9141734117bf30c4313bddfd16",
      "dc06666761f34cafaa45cbc20b0b3208"
     ]
    },
    "id": "_Ra1UwOGxOTF",
    "outputId": "52e9bc60-ed2a-4e90-97a8-c218cef4418c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdd2f684d76401eac5c6eddcc3aeca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7410a3ce72b0419395f8f1e8471d5ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593cd37ef15c41f9a69706ebd3e7441a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5_fast.py:161: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "### Model Creation \n",
    "# We use the base T5 model wich is a lighter one \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27pnaWWJakPy"
   },
   "source": [
    "## Tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOevF8JtXu4C"
   },
   "source": [
    "Small test with the tokenizer : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7M8oCoIQyYv3",
    "outputId": "48315ae4-1337-4de7-ca33-9a752c5a2051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [27, 183, 3, 9, 3061, 1712, 1, 27, 183, 3, 9, 18399, 3, 89, 3822, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer(\"I am a lovely cat\", \"I am a lively frog\")  # no padding that what there are only ones in the attention mask \n",
    "test  # 1 is the end of sequence token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZilTaPMbz6ua",
    "outputId": "0073fa61-35cf-4d5c-c8b9-d8a9eef4af1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', '', 'a', 'lovely', 'cat', '', 'I', 'am', '', 'a', 'lively', '', 'f', 'rog', '']\n",
      "I am  a lovely cat  I am  a lively  f rog \n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = [ tokenizer.decode(input, skip_special_tokens=True, clean_up_tokenization_spaces=True) # \n",
    "                    for input in test['input_ids']]\n",
    "print(decoded_sentence)\n",
    "print(\" \".join(decoded_sentence)) # we can reform the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9AYOb_x4LPc",
    "outputId": "a42611d9-1c80-40a5-ff56-c186470a9f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}\n"
     ]
    }
   ],
   "source": [
    "# special tokens\n",
    "print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVX3UK9sbkhM"
   },
   "source": [
    "T5 model on the Squad Dataset : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G8ae2j-aeBN"
   },
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ecKRxw65z4h"
   },
   "outputs": [],
   "source": [
    "# tokenisation of the dataset \n",
    "\n",
    "# for the answers , we have to change the 0 of the padding \n",
    "# to -100 we have to change them to -100\n",
    "\n",
    "class SquadDataset(Dataset): \n",
    "  \"\"\" Class which build the dataset using buy extention of the Dataset module of pytorch, \n",
    "  it takes a Dataframe into input\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "      self, \n",
    "      data : pd.DataFrame, \n",
    "      tokenizer: T5Tokenizer, \n",
    "      len_max_token_source : int = 396  ,\n",
    "      len_max_token_target : int = 40\n",
    "  ): \n",
    "    self.tokenizer = tokenizer\n",
    "    self.data      = data\n",
    "    self.len_max_token_source = len_max_token_source\n",
    "    self.len_max_token_target = len_max_token_target\n",
    "\n",
    "  def __len__(self): \n",
    "     return (len(self.data))\n",
    "  \n",
    "  def __getitem__(self, index: int): \n",
    "    data_ligne = self.data.iloc[index] # to get theitem of location idex \n",
    "\n",
    "    # we use the tokenizer \n",
    "    encoded_source = tokenizer(\n",
    "        data_ligne[\"question\"],\n",
    "        data_ligne[\"context\"],\n",
    "        max_length = self.len_max_token_source,\n",
    "        padding = \"max_length\",\n",
    "        truncation = \"only_second\",\n",
    "        return_attention_mask = True, \n",
    "        add_special_tokens = True, \n",
    "        return_tensors = \"pt\"\n",
    "\n",
    "    )\n",
    "\n",
    "    encoded_target = tokenizer(\n",
    "        data_ligne[\"text\"],\n",
    "        max_length = self.len_max_token_target,\n",
    "        padding = \"max_length\",\n",
    "        truncation = True,\n",
    "        return_attention_mask = True, \n",
    "        add_special_tokens = True, \n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "\n",
    "    labels = encoded_target[\"input_ids\"]\n",
    "    labels[labels ==0 ] = -100 #the labels, here the answers must have their label =-100\n",
    "\n",
    "    return (dict(\n",
    "        question = data_ligne['question'], \n",
    "        context  = data_ligne['context'], \n",
    "        text     = data_ligne['text'],   # the answer\n",
    "        input_ids= encoded_source ['input_ids'].flatten(),\n",
    "        attention_mask_source= encoded_source['attention_mask'].flatten(), \n",
    "        labels = labels.flatten()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLs6JK0zZKhv"
   },
   "source": [
    "## Small Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWYKDlw7NoN4"
   },
   "outputs": [],
   "source": [
    "test_dataset = SquadDataset(dataset, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRGAN31yPzCL",
    "outputId": "97e9d777-7833-401b-ac65-b90b288daa63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Saint Bernadette Soubirous\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dict(dataset.head(1))[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81J6OS3rOcO2",
    "outputId": "ed7a1ec8-b5ad-4518-d6be-7c3765725171"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'text': 'Saint Bernadette Soubirous', 'input_ids': tensor([  304,  4068,   410,     8, 16823,  3790,     3, 18280,  2385,    16,\n",
      "          507,  3449,    16,   301,  1211,  1395,  1410,    58,     1, 30797,\n",
      "          120,     6,     8,   496,    65,     3,     9,  6502,  1848,     5,\n",
      "           71,  2916,     8,  5140,  5450,    31,     7,  2045, 22161,    19,\n",
      "            3,     9,  7069, 12647,    13,     8, 16823,  3790,     5,     3,\n",
      "        29167,    16,   851,    13,     8,  5140,  5450,    11,  5008,    34,\n",
      "            6,    19,     3,     9,  8658, 12647,    13,  2144,    28,  6026,\n",
      "            3,    76, 24266,    28,     8,  9503,    96,   553,    15,  7980,\n",
      "         1980,  1212, 13285,  1496,  1280,  3021,    12,     8,  5140,  5450,\n",
      "           19,     8, 23711,  2617,    13,     8,     3, 24756,  6219,     5,\n",
      "            3, 29167,  1187,     8, 20605,  2617,    19,     8,  8554,    17,\n",
      "          235,     6,     3,     9, 17535,   286,    13,  7029,    11,  9619,\n",
      "            5,    94,    19,     3,     9, 16455,    13,     8,     3,  3844,\n",
      "           17,   235,    44,   301,  1211,  1395,     6,  1410,   213,     8,\n",
      "        16823,  3790,     3, 28285,    26,   120,  4283,    12,  2788,  8942,\n",
      "            9,    26,  1954,   264,  8371,  8283,    16,   507,  3449,     5,\n",
      "          486,     8,   414,    13,     8,   711,  1262,    41,   232,    16,\n",
      "            3,     9,  1223,   689,    24,  1979,     7,   190,   220, 12647,\n",
      "            7,    11,     8,  2540, 10576,    15,   201,    19,     3,     9,\n",
      "          650,     6,   941,  3372, 12647,    13,  3790,     5,     1,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0]), 'attention_mask_source': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([2788, 8942,    9,   26, 1954,  264, 8371, 8283,    1, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])}\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.__getitem__(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QX5uD0VtN7e4",
    "outputId": "28de863a-9b92-427d-fcbc-614298f82b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Saint Bernadette Soubirous\n",
      "tensor([  304,  4068,   410,     8, 16823,  3790,     3, 18280,  2385,    16,\n",
      "          507,  3449,    16,   301,  1211,  1395,  1410,    58,     1, 30797])\n",
      "tensor([2788, 8942,    9,   26, 1954,  264, 8371, 8283,    1, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "# retreive the infos of our dataset \n",
    "for data in test_dataset : \n",
    "  print(data[\"question\"])    # question\n",
    "  print(data['text'])\n",
    "  print(data['input_ids'][:20])\n",
    "  print(data['labels'])      # answer\n",
    "  break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWU4I3tNZOZy"
   },
   "source": [
    "## Creation of the dataframes - dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WbEqJcHaMIr"
   },
   "source": [
    "Creation of the two dataframe which will be converted in dataset in the following contructing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3KEgXq0DfXc"
   },
   "outputs": [],
   "source": [
    "def generate_answer(question): \n",
    "  source_encoding = tokenizer(\n",
    "      question[\"question\"], \n",
    "      questions \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDG0xurMvSZa"
   },
   "outputs": [],
   "source": [
    "### train dataframe\n",
    "train_dataframe      = datacontructor(questions, answers, contexts)\n",
    "\n",
    "### validation dataframe\n",
    "validation_dataframe =  datacontructor(questions_v, answers_v, contexts_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxCe2tecEOwK"
   },
   "source": [
    "## Tokenization of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRhW9hJuwoGe",
    "outputId": "2c284390-3b77-4de2-f9a1-9137e1d4d8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [822, 3, 10, 5680, 19, 16, 851, 13, 8, 7711, 3, 17084, 5140, 5450, 58, 1018, 6327, 3, 10, 16768, 450, 1427, 6, 8, 496, 65, 3, 9, 6502, 1848, 5, 71, 2916, 8, 5140, 5450, 31, 7, 2045, 22161, 19, 3, 9, 7069, 12647, 13, 8, 16823, 3790, 5, 3, 29167, 16, 851, 13, 8, 5140, 5450, 11, 5008, 34, 6, 19, 3, 9, 8658, 12647, 13, 2144, 28, 6026, 3, 76, 24266, 28, 8, 9503, 96, 553, 15, 7980, 1980, 1212, 13285, 1496, 1280, 3021, 12, 8, 5140, 5450, 19, 8, 23711, 2617, 13, 8, 3, 24756, 6219, 5, 3, 29167, 1187, 8, 20605, 2617, 19, 8, 8554, 17, 235, 6, 3, 9, 17535, 286, 13, 7029, 11, 9619, 5, 94, 19, 3, 9, 16455, 13, 8, 3, 3844, 17, 235, 44, 301, 1211, 1395, 6, 1410, 213, 8, 16823, 3790, 3, 28285, 26, 120, 4283, 12, 2788, 8942, 9, 26, 1954, 264, 8371, 8283, 16, 507, 3449, 5, 486, 8, 414, 13, 8, 711, 1262, 41, 232, 16, 3, 9, 1223, 689, 24, 1979, 7, 190, 220, 12647, 7, 11, 8, 2540, 10576, 15, 201, 19, 3, 9, 650, 6, 941, 3372, 12647, 13, 3790, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "test = tokenizer ( \"question :\" + train_dataframe.iloc[1][\"question\"] + \"context :\" + train_dataframe.iloc[1][\"context\"])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbBUYI0lyDHl"
   },
   "outputs": [],
   "source": [
    "def dataframe_tokenizer(dataframe): \n",
    "  # creation of the sequence \n",
    "  input_sequences = []\n",
    "  for i in range(0,len(dataframe)):\n",
    "      sequence = 'question: '+dataframe.iloc[i][\"question\"] +' context: '+dataframe.iloc[i][\"context\"]\n",
    "      input_sequences.append(sequence)\n",
    "  \n",
    "  max_source_length = 512\n",
    "  max_target_length = 128\n",
    "\n",
    "  # encoding\n",
    "  encoding = tokenizer(   # T5 tokenizer\n",
    "    input_sequences,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_source_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "  )\n",
    "\n",
    "  target_encoding = tokenizer(\n",
    "    dataframe[\"text\"].tolist() ,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_target_length, \n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\",\n",
    "\n",
    "  )\n",
    "\n",
    "  labels = target_encoding.input_ids\n",
    "  labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "  input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "  return ({\"input_ids\"     : input_ids, \n",
    "           \"attention_mask\": attention_mask,\n",
    "           \"labels\"        : labels})\n",
    "\n",
    "train_input       = dataframe_tokenizer(train_dataframe)\n",
    "validation_inputs = dataframe_tokenizer(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axiwGHj2Ymof",
    "outputId": "20179c28-1b2a-42f6-cc81-879caf94e289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[822,  10, 304,  ...,   0,   0,   0],\n",
       "        [822,  10, 363,  ...,   0,   0,   0],\n",
       "        [822,  10,  37,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [822,  10, 363,  ...,   0,   0,   0],\n",
       "        [822,  10, 571,  ...,   0,   0,   0],\n",
       "        [822,  10,  86,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[\"input_ids\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nml6ZAIf5J4",
    "outputId": "ce9843de-a23a-4a29-aa70-2c864a629f77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2788,  8942,     9,  ...,  -100,  -100,  -100],\n",
       "        [    3,     9,  8658,  ...,  -100,  -100,  -100],\n",
       "        [    8,  5140,  5450,  ...,  -100,  -100,  -100],\n",
       "        ...,\n",
       "        [   37, 30979,     3,  ...,  -100,  -100,  -100],\n",
       "        [30979,     3, 15291,  ...,  -100,  -100,  -100],\n",
       "        [  381,   662,     1,  ...,  -100,  -100,  -100]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_input[\"labels\"][0:400])  ## we have -100 like that it know it is labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpM6WOIEvizz"
   },
   "source": [
    "# T5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmYjEkp3Ec4Q"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407,
     "referenced_widgets": [
      "d1b7124b55fc4a1fbd5f48a1531aef97",
      "ec6e21093ec04ee7845068c311eec4aa",
      "1c1f3720962a4559b0976fa598ab1f24",
      "65ec9ae5f1b9406f991b9ee3dfbf4705",
      "558712d9f1724d99a62a027b8360ad9f",
      "f5609944cd08450db376a329af7a4029",
      "a3e0522c3bd54563998d13252419e96d",
      "d1308830d5fa4296aac76885e62d17a2",
      "b04ce181d35144718b3e8dda3c7f5c33",
      "641b99152d3c4a0b995042bb147896ca",
      "76516639ce714d2cae89d3e2b875acdb",
      "df32da84e69742a485fe29fc960c4194",
      "cecedf48b3524fea85773056555b3be3",
      "b11954568f7546aab33a028f2a4dafb9",
      "17aa731a6dbe43c69fd97748b39b7353",
      "30c9d8da7ee340aea68182022cf750ea",
      "30326e316b8d4d51ac538224f73c103d",
      "ba5957d0c84b43ffafe40df615a1f397",
      "df735f4e4cad4c918724546bbffe5e91",
      "e7b6cc7be6cb46748459e94ad46d9687",
      "f1ae172d9e9247d8b07034daada09ae0",
      "e8e81c31c5a84b66ae3677fc1e474abb"
     ]
    },
    "id": "6O5kzJdgTRz8",
    "outputId": "4009381e-6a88-42d7-e4a3-8e47f801019d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b7124b55fc4a1fbd5f48a1531aef97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df32da84e69742a485fe29fc960c4194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch number  0 :____________\n",
      "0.3186635673046112 \n",
      "\n",
      "\n",
      "\n",
      "Epoch number  1 :____________\n",
      "0.07763504981994629 \n",
      "\n",
      "\n",
      "\n",
      "Epoch number  2 :____________\n",
      "0.030573375523090363 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 6\n",
    "batch_size = 10\n",
    "batch_number = 10\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "optimizer =AdamW(model.parameters(), lr=0.0001)\n",
    "for i in (range(3)):\n",
    "  print('\\n')\n",
    "  for j in range(0,10):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = model(\n",
    "                 input_ids     = train_input     [\"input_ids\"][j*batch_size:((j+1)*batch_size)], \n",
    "                 attention_mask= train_input[\"attention_mask\"][j*batch_size:((j+1)*batch_size)], \n",
    "                 labels        = train_input        [\"labels\"][j*batch_size:((j+1)*batch_size)]\n",
    "                 ).loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(\"Epoch number \",  i ,\":____________\")\n",
    "  print(loss.item(), '\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sj8SsKv2C29s",
    "outputId": "0694a34c-6c5e-4d6e-fca7-1591be8c8970"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/content/gdrive/MyDrive/model/T5-custom/tokenizer_config.json',\n",
       " '/content/gdrive/MyDrive/model/T5-custom/special_tokens_map.json',\n",
       " '/content/gdrive/MyDrive/model/T5-custom/tokenizer.json')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/content/gdrive/MyDrive/model/T5-custom'\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQp3m3lxEjEi"
   },
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "d77fc2e965c44913900d4afc92a8ea7e",
      "34e764c4a2244c5baf9b401a60055c9c",
      "63cf8ff7f6854461b5ea59e48f0eaf80",
      "6fe47d9b9db845cf8bc6953d328e0df3",
      "2fcf87010fed45ba83e14ef416573596",
      "42ce59cf162648339ee635983e26d8ba",
      "b969f6c49c2a4b26879ecce84a67cee0",
      "2835612c1da24bc1b75fb58e50524a1d",
      "18d6f44f041d4f28aa6253facfc1440c",
      "884a6b743e1e48fa8b3e5df3e2be92f0",
      "d1daa687779f44db83f04dbb85c4fe2b",
      "09d49858f34a43188ab12e66da323645",
      "6bfbc1ffb4624f03a977a180db6b7dce",
      "7bba2cf8db6446cb9f98e5e9fbd7c83f",
      "b1ecd6d56b9d407b9e6198eb317fd030",
      "e9413b98ae6643e2b478ec3087aad8d7",
      "0ef3824c3f2e4f2797cc5c072f300ec7",
      "12f9bb884a204ea2a03c941290c0cae5",
      "155a02655273460db835d0504daafbc1",
      "33e1abbb6804466a9ba5e40f9ea6b5e9",
      "070b180fb58a4de8b6e78ed1573efd8e",
      "859044fcaebc416bb62c6057060c26b5"
     ]
    },
    "id": "XfRt0d1hadRY",
    "outputId": "65ba5d7f-676f-4ed4-c81c-226b4f7785c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77fc2e965c44913900d4afc92a8ea7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d49858f34a43188ab12e66da323645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.8703878902554399, 'f1': 0.4862559908091554}\n"
     ]
    }
   ],
   "source": [
    "model_path = '/content/gdrive/MyDrive/model/T5-custom'\n",
    "T5_tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model_T5 = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "def validation(train_dataframe):  \n",
    "  formatted_predictions = list()\n",
    "  references = list()\n",
    "  for index in range(len(train_dataframe)):\n",
    "      data_ligne = train_dataframe.iloc[index]\n",
    "      \n",
    "      inputs           = tokenizer('question: '+data_ligne[\"question\"] +' context: '+data_ligne[\"context\"]\n",
    "                                  , return_tensors=\"pt\"\n",
    "                                  , padding=True)\n",
    "      output_sequences = model_T5.generate(\n",
    "                input_ids      = inputs[\"input_ids\"],\n",
    "                attention_mask = inputs[\"attention_mask\"],\n",
    "                do_sample      = False,  # disable sampling to test if batching affects output\n",
    "                )\n",
    "\n",
    "      dict_result_T5 = {'id':index, \n",
    "                        'prediction_text': tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0]}\n",
    "\n",
    "      dict_reality   = {'answers':{\n",
    "                                    'answer_start':data_ligne[\"answer_start\"]*3, \n",
    "                                    'text':data_ligne[\"text\"]*3},\n",
    "                        'id': index\n",
    "      }\n",
    "      formatted_predictions.append(dict_result_T5)\n",
    "      references.append(dict_reality)\n",
    "  metric = load_metric(\"squad\")\n",
    "  print(metric.compute(predictions=formatted_predictions, references=references))\n",
    "  return (formatted_predictions,references )\n",
    "\n",
    "formatted_predictions, references = validation(validation_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMrlU5FiQy4w",
    "outputId": "fc2610c6-6cc5-4d82-e2eb-2dd5f65b1d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.8703878902554399, 'f1': 0.4862559908091554}\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "print(metric.compute(predictions=formatted_predictions, references=references))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YN9aiH3D6b1"
   },
   "source": [
    "The scores are really low because usually T5 get one are two other word and not the exact answer. Nevertheless those score are strangely low so we look at manulaly the percentage of exact match and the pourcentage of time the answer proposed by T5 is in the real answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mrn7Mj_sFtH",
    "outputId": "a8867587-3d92-41e8-da5f-d0018c082d77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:56<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "exact match : 64.6 %\n",
      "T5 answer is present in the real answer : 71.6 %\n",
      "The real answer in in T5 76.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_match = 0\n",
    "real_answeri_in_T5 = 0 \n",
    "T5_in_real = 0\n",
    "size = 500\n",
    "for i in tqdm(range (0, size)): \n",
    "  data_ligne = validation_dataframe.iloc[i]\n",
    "  inputs           = T5_tokenizer('question: '+data_ligne[\"question\"] +' context: '+data_ligne[\"context\"]\n",
    "                                    , return_tensors=\"pt\"\n",
    "                                    , padding=True)\n",
    "  output_sequences = model_T5.generate(\n",
    "                  input_ids      = inputs[\"input_ids\"],\n",
    "                  attention_mask = inputs[\"attention_mask\"],\n",
    "                  do_sample      = False,  # disable sampling to test if batching affects output\n",
    "                  )\n",
    "\n",
    "  predicted_text_T5 = T5_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0]\n",
    "  #print(\"======================================\")\n",
    "  #print(\"reel answer: \" , data_ligne[\"text\"])\n",
    "  #print(\" T5 answer : \", predicted_text_T5 , '\\n')\n",
    "  if (data_ligne[\"text\"] ==predicted_text_T5 ):\n",
    "    exact_match+=1\n",
    "  if (predicted_text_T5 in data_ligne[\"text\"] ):\n",
    "    T5_in_real += 1\n",
    "  if ( data_ligne[\"text\"] in predicted_text_T5):\n",
    "     real_answeri_in_T5 += 1\n",
    "print('\\n')\n",
    "print( \"exact match :\" , exact_match*100 / size , \"%\")\n",
    "print( \"T5 answer is present in the real answer :\" , T5_in_real*100 / size ,\"%\")\n",
    "print( \"The real answer in in T5\" , real_answeri_in_T5*100 / size ,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppBv_xBpuEz8"
   },
   "source": [
    "**==============================================================================================================**\n",
    "\n",
    "So as we can see above : \n",
    "$$\\text{ 64.6% of the time the answer and T5 answer are exactly the same. }$$\n",
    "$$\\text{And in 71.6% of the time the aswer proposed by T5 is in the real answer, and 76.6% of the time the real answer is in T5  }$$\n",
    "\n",
    "**==============================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrRRBB-kEn8m"
   },
   "source": [
    "# Comparison between BERT and T5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCLCGQrBqH3t"
   },
   "source": [
    "> **Problem 3.2** *(2 points)* Compare a few examples between BERT and T5 and explain how they differ. Note that `T5-small` is a smaller model than `BERT-base-cased`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVQSYryVKAwR",
    "outputId": "2310ed9e-0d03-4f23-b199-795c5120420c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvVEN8IYIfel"
   },
   "outputs": [],
   "source": [
    "## Make a dataset class to use the dataloader method after : \n",
    "import torch \n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "  \n",
    "  def __getitem__(self, index) -> dict: \n",
    "    return ({ key: torch.tensor(value[index]) for key, value in self.encodings.items() })\n",
    "  \n",
    "  def __len__(self)->int: \n",
    "    return (len(self.encodings.input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NSTVtS7BvVSD",
    "outputId": "8a1c391f-a506-40a8-ac1a-44b66ed3dace"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n",
      "reel answer:  Denver Broncos\n",
      "BERT answer:  Denver Broncos\n",
      " T5 answer :  Denver Broncos \n",
      "\n",
      "======================================\n",
      "reel answer:  Carolina Panthers\n",
      "BERT answer:  \n",
      " T5 answer :  Carolina Panthers \n",
      "\n",
      "======================================\n",
      "reel answer:  Santa Clara, California\n",
      "BERT answer:  San Francisco\n",
      " T5 answer :  San Francisco Bay Area \n",
      "\n",
      "======================================\n",
      "reel answer:  Denver Broncos\n",
      "BERT answer:  Denver Broncos\n",
      " T5 answer :  American Football Conference \n",
      "\n",
      "======================================\n",
      "reel answer:  gold\n",
      "BERT answer:  golden anniversary\n",
      " T5 answer :  gold \n",
      "\n",
      "======================================\n",
      "reel answer:  \"golden anniversary\"\n",
      "BERT answer:  golden anniversary\n",
      " T5 answer :  the \"golden anniversary\" \n",
      "\n",
      "======================================\n",
      "reel answer:  February 7, 2016\n",
      "BERT answer:  February 7\n",
      " T5 answer :  February 7, 2016 \n",
      "\n",
      "======================================\n",
      "reel answer:  American Football Conference\n",
      "BERT answer:  Super Bowl 50 was an American football game to determine the champion of the National Football\n",
      " T5 answer :  Super Bowl L \n",
      "\n",
      "======================================\n",
      "reel answer:  \"golden anniversary\"\n",
      "BERT answer:  golden anniversary\n",
      " T5 answer :  the \"golden anniversary\" \n",
      "\n",
      "======================================\n",
      "reel answer:  American Football Conference\n",
      "BERT answer:  American football game to determine the champion of the National Football\n",
      " T5 answer :  American Football Conference \n",
      "\n",
      "======================================\n",
      "reel answer:  February 7, 2016\n",
      "BERT answer:  February 7\n",
      " T5 answer :  February 7, 2016 \n",
      "\n",
      "======================================\n",
      "reel answer:  Denver Broncos\n",
      "BERT answer:  Denver Broncos\n",
      " T5 answer :  Denver Broncos \n",
      "\n",
      "======================================\n",
      "reel answer:  Levi's Stadium\n",
      "BERT answer:  Levi '\n",
      " T5 answer :  Levi's Stadium \n",
      "\n",
      "======================================\n",
      "reel answer:  Santa Clara\n",
      "BERT answer:  \n",
      " T5 answer :  Santa Clara, California \n",
      "\n",
      "======================================\n",
      "reel answer:  Super Bowl L\n",
      "BERT answer:  Super Bowl\n",
      " T5 answer :  Super Bowl L \n",
      "\n",
      "======================================\n",
      "reel answer:  2015\n",
      "BERT answer:  2015 season\n",
      " T5 answer :  the 2015 season \n",
      "\n",
      "======================================\n",
      "reel answer:  2015\n",
      "BERT answer:  2015 season\n",
      " T5 answer :  2016 \n",
      "\n",
      "======================================\n",
      "reel answer:  Santa Clara\n",
      "BERT answer:  \n",
      " T5 answer :  Santa Clara, California \n",
      "\n",
      "======================================\n",
      "reel answer:  Levi's Stadium\n",
      "BERT answer:  Levi '\n",
      " T5 answer :  Levi's Stadium \n",
      "\n",
      "======================================\n",
      "reel answer:  24–10\n",
      "BERT answer:  \n",
      " T5 answer :  24–10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Examples with Bert : \n",
    "\n",
    "# load the model \n",
    "model_path = '/content/gdrive/MyDrive/model/bert-custom'\n",
    "model_BERT = BertForQuestionAnswering.from_pretrained(model_path)\n",
    "Bert_tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "encoded   = Bert_tokenizer(context_matrix_v[0:20], questions_matrix_v[0:20],truncation=True, padding='max_length')\n",
    "\n",
    "\n",
    "test_data = Dataset(encoded)\n",
    "test_loader = DataLoader( test_data)\n",
    "start_pred=[]\n",
    "end_pred  =[]\n",
    "for batch in tqdm (test_loader): \n",
    "  with torch.no_grad():\n",
    "    input_ids      = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    outputs = model_BERT(input_ids, attention_mask = attention_mask)\n",
    "    start_pred.append(torch.argmax(outputs['start_logits'], dim = 1))\n",
    "    end_pred.append(torch.argmax(outputs['end_logits'], dim = 1))\n",
    "\n",
    "\n",
    "model_path = '/content/gdrive/MyDrive/model/T5-custom'\n",
    "T5_tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "model_T5 = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "for i in range (0, 20): \n",
    "  data_ligne = validation_dataframe.iloc[i]\n",
    "  inputs           = T5_tokenizer('question: '+data_ligne[\"question\"] +' context: '+data_ligne[\"context\"]\n",
    "                                    , return_tensors=\"pt\"\n",
    "                                    , padding=True)\n",
    "  output_sequences = model_T5.generate(\n",
    "                  input_ids      = inputs[\"input_ids\"],\n",
    "                  attention_mask = inputs[\"attention_mask\"],\n",
    "                  do_sample      = False,  # disable sampling to test if batching affects output\n",
    "                  )\n",
    "\n",
    "  predicted_text_T5 = T5_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0]\n",
    "  predicted_text_BERT = \" \".join(Bert_tokenizer.convert_ids_to_tokens(encoded['input_ids'][i][int(start_pred[i]):(int(end_pred[i])+1)]))\n",
    "  print(\"======================================\")\n",
    "  print(\"reel answer: \" , data_ligne[\"text\"])\n",
    "  print(\"BERT answer: \", predicted_text_BERT)\n",
    "  print(\" T5 answer : \", predicted_text_T5 , '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVSY2UBIEz68"
   },
   "source": [
    "We can see that T5 tend to take more words into the answer, one or two tokens before and after the answer as with those exemples: \n",
    "\n",
    " **reel answer:**  Santa Clara\n",
    "\n",
    " **T5 answer :**Santa Clara, California\n",
    "\n",
    "**reel answer:** 2015\n",
    "\n",
    "**T5 answer :** the 2015 season\n",
    "\n",
    "Where the answer is correct but not exactly what is expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3SCr8SjqhfI"
   },
   "source": [
    "> **Problem 3.3** *(2 points)* Generation model is known to often suffer from hallucination (see https://ehudreiter.com/2018/11/12/hallucination-in-neural-nlg/). Can you find or create one example that causes this phenomenon in T5? How does BERT behave with the same example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5V-JG5e2KDGI",
    "outputId": "d322a5cb-c684-4609-a974-7614bf8e4c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was the testing of the LM during Apollo 5 a failure or a success?\n",
      "('Apollo 5 (AS-204) was the first unmanned test flight of LM in Earth orbit, '\n",
      " 'launched from pad 37 on January 22, 1968, by the Saturn IB that would have '\n",
      " 'been used for Apollo 1. The LM engines were successfully test-fired and '\n",
      " 'restarted, despite a computer programming error which cut short the first '\n",
      " 'descent stage firing. The ascent engine was fired in abort mode, known as a '\n",
      " '\"fire-in-the-hole\" test, where it was lit simultaneously with jettison of '\n",
      " 'the descent stage. Although Grumman wanted a second unmanned test, George '\n",
      " 'Low decided the next LM flight would be manned.')\n",
      "{'text': ['success', 'success', 'LM engines were successfully test-fired and restarted', 'successfully'], 'answer_start': [194, 194, 178, 194]}\n",
      "BERT failure or a success\n",
      "T5   failure\n"
     ]
    }
   ],
   "source": [
    "print(questions_matrix_v[3999])\n",
    "pprint(context_matrix_v[3999])\n",
    "print(answer_matrix_v[3999])\n",
    "\n",
    "encoded   = Bert_tokenizer(context_matrix_v[3999:4000], questions_matrix_v[3999:4000],truncation=True, padding='max_length')\n",
    "\n",
    "#BERT\n",
    "test_data = Dataset(encoded)\n",
    "test_loader = DataLoader( test_data)\n",
    "start_pred=[]\n",
    "end_pred  =[]\n",
    "for batch in  (test_loader): \n",
    "  with torch.no_grad():\n",
    "    input_ids      = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    outputs = model_BERT(input_ids, attention_mask = attention_mask)\n",
    "    start_pred.append(torch.argmax(outputs['start_logits'], dim = 1))\n",
    "    end_pred.append(torch.argmax(outputs['end_logits'], dim = 1))\n",
    "predicted_text_BERT = \" \".join(Bert_tokenizer.convert_ids_to_tokens(encoded['input_ids'][0][int(start_pred[0]):(int(end_pred[0])+1)]))\n",
    "\n",
    "#T5\n",
    "data_ligne = validation_dataframe.iloc[3999]\n",
    "inputs           = T5_tokenizer('question: '+data_ligne[\"question\"] +' context: '+data_ligne[\"context\"]\n",
    "                                    , return_tensors=\"pt\"\n",
    "                                    , padding=True)\n",
    "output_sequences = model_T5.generate(\n",
    "                  input_ids      = inputs[\"input_ids\"],\n",
    "                  attention_mask = inputs[\"attention_mask\"],\n",
    "                  do_sample      = False,  # disable sampling to test if batching affects output\n",
    "                  )\n",
    "predicted_text_T5 = T5_tokenizer.batch_decode(output_sequences, skip_special_tokens=True)[0]\n",
    "\n",
    "print(\"BERT\",predicted_text_BERT)\n",
    "print(\"T5  \",  predicted_text_T5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4jZr-VQJ-_r"
   },
   "source": [
    "We can see here that BERT and T5 come up with an answer even if the answer is not present in the text. More over T5 got it wrong and BERT doesn't answer properly to the question. That is a caise of allucination. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GSPZeNGjxre"
   },
   "source": [
    "# 4. Dense Retrieval\n",
    "\n",
    "Remember that in Assignment 2, you created a simple dense retrieval model that just averages BERT embeddings? In this part of the assignment, you will create a more practical dense retrieval system with the `[cls]` output of BERT. This means you use the BERT encoder to map each quesiton to a vector and the corresponding paragraph to another vector, and train it so that their inner product is higher than that of unrelated pairs. There are several ways to approach this problem and you are free to design however you like (just note that you need to use inner product, not L2). Note that Dense Passage Retrieval (https://arxiv.org/abs/2004.04906), and in particular In-Batch Negative training, is one of the simplest and effective ways and it is highly recommended to refer to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEHENbt-t7Fa"
   },
   "source": [
    "> **Problem 4.1** *(3 points)* Create a BERT-based (output, not just the embedding) dense retrieval model that finetunes on SQuAD and evaluate it on the validation data, in a similar setting to that of Assignment 2 (i.e. measure Recall@10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru3PlJcyPD72"
   },
   "source": [
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZjIPhdXFtim"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cuaNvVsGLwdW"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kJmmWyDPGOn"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "f030d936921c4591a8ef3edba89b750c",
      "a2ffc6d9053d4d8facbe973fbc5bab1a",
      "ab983112a7414d43a24ba4d02a683105",
      "1bc7cb4462fe4190b654ff4819d46b52",
      "de23f543b15f454db25d491d8e6b2b81",
      "e6142f4f150e4313a8dab16931fc30a7",
      "cf3adb491cd04ed0a25b326670161573",
      "233a192d4fd94a19badc772de8462a78",
      "530e561f1f724861946de2e2b5774f76",
      "6aac9ba5650c47f48aba0cb78c0d8486",
      "2655501bef124208aefff1e732a40432",
      "712fe1d4ed644ef2b2184f6989a4e543",
      "2f6e070234f149cdb068ddde24be7604",
      "9929aef74d85422fb016cb968a55c0c7",
      "72464554e5cf4936ab6ba338d487e8aa",
      "dccacf7c834b41119e3a4191a8801937",
      "1c0f3efb519946e1ae3474c8166d012d",
      "375064928e2741639ef75998eefb7f64",
      "ee7b45c4c4e44168836bf21f9f6022c9",
      "6f337c72a32e4d46aac10af14bbcbd03",
      "d7fb8429b5844cf1a38b547c784b05f6",
      "10e6017dec08463e86e5aacbd70d08a4",
      "d166f9d82eed4bdb824e1c8de20dfe65",
      "56f0f76a767f43e0865552fe4096b582",
      "2bd6eedbaeab4250a0086c8c68ba4f3c",
      "233997f8a5f040b3bc9b5cab1dc0fd06",
      "4cec98c851f4486692d7f709f3839aed",
      "985db720fd88436488815255f353abee",
      "738b31eca10342acac8cf76270212c2c",
      "4b46b9b7125c42ad84619c8b1f435c3d",
      "1605d3bf111845c58df7386f1d1be60e",
      "9ec27e8f6478434f89d89576aaadc677",
      "aa74be5f8d91493ba592dd59af95af43",
      "1399ead84a2f45aea0160d86de31cd60",
      "68a4b8e98f5441bb840ce429ae675abc",
      "d6603dabc5a745e8a6e683073adbdb89",
      "9d53ca1058454bbdba98ecf7a315241b",
      "a46e3eb5afe24660a4f84f2271e0b2d0",
      "ea3882d0f83c46cc8d255d69c981cc4c",
      "899ff58b5aae44279c1438371615cba9",
      "11f64f8841454935b3eb8d6a19e71d5d",
      "cdad12534c844ca7ad3abf662a6284b9",
      "2dd14af33437453b851229608a03b31f",
      "696651e4dc6741bf8475c87c7bf5ae11",
      "e39f387e549e488ca353b92854b8c8f8",
      "6fdf672f2cb24de0acbdab12c6b4ea48",
      "647b34db9c0744b3a8023973637b1dde",
      "8c1043b3eb684bc3835cb693102f4429",
      "f8a3fc5d917e430490bf42324d5a2d83",
      "5ca8bd2a2b1846c0ba1cced8431f185e",
      "d336f39efec84b4d93883ed09a124098",
      "7f90b9613bcf43b9bac7b764c77f0df7",
      "42a52e4894614038b10d7fa6a1a5bad9",
      "9cec068c0fe0403790b95f3b09f742e1",
      "854b8fe9b94843668d05fc2755eabaf5",
      "44d435e8d74b4f76998be410afd34091",
      "c5e74c666ba64ef4b991668f303ebea7",
      "f3fe6711b9da46f7b713ff79794b18bb",
      "b77945171d7448e0b752f0ffabb22e5c",
      "fe43c1d2776347b7bdba864e82c865cc",
      "3110feb0609748f9b48243988c13f824",
      "8d7b717611ec40a6ae268455dd6b3d8d",
      "b13a512c5a2c4dd28ce4be5eaf916be8",
      "77b07f25d0cf411d81542413e7d51fe4",
      "043aab8b054845e48ad3f16effc4b920",
      "d8342957072d4294ab13a2ea0e2114c1"
     ]
    },
    "id": "fBslOx06L2Ka",
    "outputId": "e28000b9-ff75-4598-a73c-19d8059d728a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f030d936921c4591a8ef3edba89b750c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/399 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712fe1d4ed644ef2b2184f6989a4e543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d166f9d82eed4bdb824e1c8de20dfe65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1399ead84a2f45aea0160d86de31cd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f387e549e488ca353b92854b8c8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d435e8d74b4f76998be410afd34091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siCEd_MjL-JD"
   },
   "outputs": [],
   "source": [
    "light_contexts  = context[0:1000]\n",
    "light_questions = questions[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ei0Vx0HbOxOk"
   },
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "encoded_context  = tokenizer(light_contexts, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "\n",
    "encoded_question = tokenizer(light_questions, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAMwUzYDWOLr",
    "outputId": "d528b88a-96ab-4cce-c6b5-d0d09866637c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2000,  3183,  ...,     0,     0,     0],\n",
       "        [  101,  2054,  2003,  ...,     0,     0,     0],\n",
       "        [  101,  1996, 13546,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2129,  2172,  ...,     0,     0,     0],\n",
       "        [  101,  2054,  7064,  ...,     0,     0,     0],\n",
       "        [  101,  2054,  2106,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usyaqp3uPKq3"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhtCsZly-aU8"
   },
   "outputs": [],
   "source": [
    "\n",
    "#passage_encoder = TFAutoModel.from_pretrained(\"nlpconnect/dpr-ctx_encoder_bert_uncased_L-12_H-128_A-2\")\n",
    "#query_encoder = TFAutoModel.from_pretrained(\"nlpconnect/dpr-question_encoder_bert_uncased_L-12_H-128_A-2\")\n",
    "\n",
    "#p_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/dpr-ctx_encoder_bert_uncased_L-12_H-128_A-2\")\n",
    "#q_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/dpr-question_encoder_bert_uncased_L-12_H-128_A-2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0775621783564bee9d298bfcd8b199b8",
      "decdf34e46064812b8a79e2af61bc883",
      "e4bbb4323e4f4dcab527d31760317f1d",
      "22ccb831100e419895b68b3ef6e1dc94",
      "d4e018985d484fcba4759af009d113f8",
      "1c5d145d73d34673859f5883531c9d8a",
      "3af54e1f442f492383d3c4bb44849283",
      "d2085fcc8e4849ae9c334712c738e522",
      "f2683b3ee1fa47488e3486f02e7ac2fe",
      "edb27b27e75e482d9cdbd1eeebed8ee6",
      "4097b168f3f548f6ba1a3fa10d32909b"
     ]
    },
    "id": "h62Bi8X-a244",
    "outputId": "cd9c5425-0abc-499b-a4b3-5adb70f94d97"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0775621783564bee9d298bfcd8b199b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_c     = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model_q     = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "\n",
    "optimizer_c = optim.Adam(model_c.parameters(), lr=0.0001)\n",
    "optimizer_q = optim.Adam(model_q.parameters(), lr=0.0001)\n",
    "model_c.to('cuda')\n",
    "model_q.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xn6cjrJDOl5d"
   },
   "outputs": [],
   "source": [
    "\"\"\" from https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens \"\"\"\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Irj1Ir4WGfd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def shuffle(c:torch.tensor, q:torch.tensor): \n",
    "  idx = torch.randperm(q.shape[0])\n",
    "  permuted_c = c[idx].view(c.size())\n",
    "  permuted_q = q[idx].view(q.size())\n",
    "  return permuted_c, permuted_q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1barjoz-7fhQ",
    "outputId": "ec5473db-91cd-4439-dc82-01dafda4c184"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 428])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_context['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DD68Sg6t6niQ",
    "outputId": "425760de-1faa-4fa5-8f65-242d3fb008af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 31])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_question['input_ids'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frjn5bCTOh53",
    "outputId": "08993354-dc3d-4f90-f4b8-09f78ea546eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 72/72 [01:35<00:00,  1.32s/it, loss=1.79]\n",
      "Epoch 1: 100%|██████████| 72/72 [01:34<00:00,  1.32s/it, loss=1.79]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch \n",
    "n_epochs = 2\n",
    "batch_size = 14\n",
    "\"\"\"Without sentence-transformers, you can use the model like this: First, you pass\n",
    " your input through the transformer model, then you have to apply the right \n",
    " pooling-operation on-top of the contextualized word embeddings.\n",
    "\"\"\"\n",
    "for epoch in range(n_epochs):\n",
    "  loop = tqdm(range (0, len(light_questions),batch_size ))\n",
    "  for  index in loop:\n",
    "      optimizer_c.zero_grad()\n",
    "      optimizer_q.zero_grad()\n",
    "\n",
    "      #model_output_context = model(**encoded_context.to('cuda'))\n",
    "      #model_output_question = model(**encoded_question.to('cuda'))\n",
    "      #model_output_context  = model_c(**encoded_context[index:(index+batch_size)].to('cuda'))\n",
    "      #model_output_question = model_q(**encoded_question[index:(index+batch_size)].to('cuda'))\n",
    "      \n",
    "      batch_c , batch_q = shuffle(encoded_context['input_ids'][index:(index+batch_size)] , \n",
    "                                  encoded_question['input_ids'][index:(index+batch_size)])\n",
    "      model_output_context  = model_c(batch_c.to('cuda')).pooler_output.to('cuda')\n",
    "      model_output_question = model_q(batch_q.to('cuda')).pooler_output.to('cuda')\n",
    "      #print(model_output_question)\n",
    "      #print(\"output question epoch\" , i, '\\n',  model_output_question[0][0].size())\n",
    "      \n",
    "      ### Perform pooling. In this case, max pooling.\n",
    "      #context_embeddings  = mean_pooling(model_output_context, encoded_context['attention_mask'][index:(index+batch_size)])\n",
    "      #question_embeddings = mean_pooling(model_output_question, encoded_question['attention_mask'][index:(index+batch_size)])\n",
    "      #print(torch.eq(context_embeddings, question_embeddings))\n",
    "      #print(context_embeddings)\n",
    "      #print(question_embeddings)\n",
    "      \n",
    "      ### Inner product\n",
    "      # as said in the subject, we cannot use the L2, we have to use the inner product \n",
    "      #between the embedded questions and the context \n",
    "      similarity = torch.mm(model_output_question,model_output_context.T) \n",
    "      # we obatin a tensor (tensor([[116.0925, 116.0925, 116.0925, 116.0925, 116.0925,  81.7312,  81.7312,\n",
    "      #      81.7312,  81.7312,  81.7312],  -> question 1 \n",
    "      #    [ 93.6791,  93.6791,  93.6791,  93.6791,  93.6791,  35.1938,  35.1938,\n",
    "      #      35.1938,  35.1938,  35.1938],)  -> question 2  where the score is hirgher for the context of the question \n",
    "      #\n",
    "\n",
    "      ### In batch negative samples\n",
    "      if len(model_output_question.size()) > 1: # if there is no batch this loop is useless \n",
    "          q_num = model_output_question.size(0)\n",
    "          scores = similarity.view(q_num, -1)  #we change the shape of similarity like that it has qnum lines\n",
    "      #print(\"sc\" , scores.size()) # line = question column = context \n",
    "      softmax_scores = F.log_softmax(scores, dim=1).to('cuda') # solftmax on the input of the loss\n",
    "      #softmax_scores = F.log_softmax(similarity, dim=1)  # not somilar are spread aprart while similar are cloth to 0 \n",
    "      #print(\"similarity epoch :\", i, ' : \\n',  similarity[:10,:10 ]) \n",
    "      # square matrix = num question x num context  (with num context = questions) if no batching\n",
    "      \n",
    "      loss = F.nll_loss(\n",
    "          softmax_scores,\n",
    "          torch.tensor([j for j in range(softmax_scores.shape[0])]).to('cuda'), \n",
    "          # if 14 questions tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13]) because eacu question \n",
    "          # must be afficiated to the context on the diagonal of the embedding must be such as the score  has to be higher on the \n",
    "          # diagonale, question 1 has the context 5 the higher score is located in position (5,5) \n",
    "          reduction=\"mean\",\n",
    "      )\n",
    "      \n",
    "      loss.backward()\n",
    "      optimizer_c.step()\n",
    "      optimizer_q.step()\n",
    "      loop.set_description(f'Epoch {epoch}')\n",
    "      loop.set_postfix(loss = loss.item())\n",
    "      if index == (len(light_questions)-1) :\n",
    "        print(\" epoch \",i ,\"loss : \" , loss.item())\n",
    "        print(\"========================\")\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jpp4DFsUtoeZ",
    "outputId": "fcb529aa-fbd9-401c-f826-eb78670a48b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gECxK-magJl0"
   },
   "outputs": [],
   "source": [
    "\n",
    "#model_path = '/content/gdrive/MyDrive/model/Bert_DRP_c'\n",
    "#model_c.save_pretrained(model_path)\n",
    "#tokenizer.save_pretrained(model_path)\n",
    "\n",
    "#model_path = '/content/gdrive/MyDrive/model/Bert_DRP_q'\n",
    "#model_q.save_pretrained(model_path)\n",
    "#tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTVUstrGhcmE",
    "outputId": "f32a290b-9c10-4be0-a844-3081fad6597f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7f9980d84d70> <built-in method size of Tensor object at 0x7f9980d84e30>\n",
      "tensor([[286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [286.8829],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [289.4887],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [281.3840],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520],\n",
      "        [283.8520]], device='cuda:0')\n",
      "tensor(30, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "light_context_v = context_v[0:100]\n",
    "light_questions_v = questions_v[0:100]\n",
    "encoded_context_v  = tokenizer(light_context_v, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "\n",
    "encoded_question_v = tokenizer(light_questions_v, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "model_q.eval()\n",
    "model_c.eval()\n",
    "with torch.no_grad():\n",
    "     model_output_context_v  = model_c(encoded_question_v['input_ids'][0:1].to('cuda')).pooler_output.to('cuda')\n",
    "     model_output_question_v = model_q(encoded_context_v['input_ids'].to('cuda')).pooler_output.to('cuda')\n",
    "     print(model_output_context_v.size, model_output_question_v.size)\n",
    "     similarity = torch.mm(model_output_question_v,model_output_context_v.T) \n",
    "     print(similarity)\n",
    "     context_index = torch.argmax(similarity)\n",
    "     print(context_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrGlIVWzDuwy",
    "outputId": "61a1ccf1-facc-40b7-fe66-dd4e858d1029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.5102e-01, -2.3657e-01,  9.7032e-01,  3.5870e-01, -8.0167e-01,\n",
      "         -4.1634e-01,  6.8466e-01,  3.8951e-01,  7.7361e-01, -9.7005e-01,\n",
      "          5.4211e-01, -8.5508e-01,  9.2920e-01, -5.6524e-01,  8.4696e-01,\n",
      "         -5.0329e-02,  7.8031e-02, -5.1392e-01,  4.0507e-01, -6.3107e-01,\n",
      "          2.8595e-01, -9.8132e-01,  7.4457e-01,  3.8812e-01,  4.6911e-01,\n",
      "         -9.5448e-01, -1.4167e-01,  8.4001e-01,  8.8603e-01,  4.2925e-01,\n",
      "         -6.2648e-01,  4.4076e-01, -8.6885e-01, -4.7645e-01,  9.5903e-01,\n",
      "         -8.4991e-01,  9.6467e-02, -6.8145e-01, -4.6164e-01, -2.5775e-01,\n",
      "         -7.3630e-01,  3.7418e-01,  1.5683e-01, -1.5913e-01, -5.5493e-01,\n",
      "         -5.5733e-01, -4.5068e-01,  4.7447e-01, -6.5579e-01, -9.5915e-01,\n",
      "         -8.9668e-01, -9.7354e-01,  3.5796e-01,  3.0211e-01,  3.5895e-01,\n",
      "          5.9699e-01,  1.6382e-01,  3.8684e-01, -1.7154e-01, -5.6182e-01,\n",
      "         -6.7086e-01,  1.5218e-01,  7.8381e-01, -6.4030e-01, -9.3230e-01,\n",
      "         -9.4135e-01, -3.4329e-01, -3.8417e-01, -1.9158e-01,  3.3397e-01,\n",
      "          6.1719e-01,  3.0825e-01,  2.3109e-01, -3.3808e-01, -8.3253e-01,\n",
      "          3.9923e-01,  6.4048e-02,  2.0009e-01,  1.8580e-01, -8.8345e-01,\n",
      "         -9.3284e-01, -7.0137e-01, -1.0385e-01,  8.2423e-01, -7.9568e-01,\n",
      "         -2.5648e-01,  7.5743e-02, -3.2369e-01, -9.4374e-01,  4.8623e-01,\n",
      "         -1.6262e-01, -4.2168e-01, -8.6637e-01, -1.2574e-01, -1.2615e-01,\n",
      "          2.4069e-01, -2.9605e-01,  9.3054e-01, -2.4823e-01,  3.3573e-01,\n",
      "          3.0698e-01, -4.8403e-01, -8.5525e-02, -3.2393e-01,  2.4694e-01,\n",
      "         -3.4214e-01, -1.3396e-01,  9.7883e-02, -1.5228e-01,  4.7223e-01,\n",
      "         -4.5780e-02, -3.0624e-01,  2.5769e-01, -8.7872e-01,  6.0648e-01,\n",
      "         -3.5521e-01, -9.0077e-01,  1.1392e-01, -9.1690e-01,  2.8136e-01,\n",
      "          3.1941e-01, -3.4217e-01,  8.9533e-01,  7.2059e-01,  3.2712e-01,\n",
      "         -3.2917e-01,  9.5364e-01, -2.0135e-01,  2.4339e-01,  2.5320e-01,\n",
      "          1.1829e-01, -1.2185e-01, -8.9540e-01, -7.3873e-01,  4.6824e-01,\n",
      "          8.7912e-01,  2.0035e-01,  2.6775e-01, -3.9883e-01,  7.3308e-01,\n",
      "          3.7074e-01,  1.5411e-01, -7.9372e-01, -4.2585e-01, -3.4374e-01,\n",
      "          3.3967e-01, -5.2928e-01,  4.2641e-01,  4.5164e-01, -7.5247e-02,\n",
      "          7.0372e-01, -4.6353e-01,  8.5500e-01, -8.1648e-01, -5.9768e-01,\n",
      "          7.5610e-01,  6.8384e-01,  9.5568e-01,  7.7648e-01, -3.8418e-01,\n",
      "         -1.4963e-01,  5.2099e-01, -5.4843e-01,  3.6164e-01,  4.1559e-03,\n",
      "          4.3462e-01, -7.8887e-02,  2.9407e-01, -6.1932e-01, -4.2666e-02,\n",
      "          3.8141e-01, -3.0437e-01,  9.3802e-01, -8.8740e-01, -3.0007e-01,\n",
      "          1.6020e-01,  9.3273e-01,  6.2464e-01,  2.9549e-01, -5.5471e-01,\n",
      "         -4.2058e-01, -1.6255e-01, -7.5678e-01,  8.4216e-01, -3.1868e-01,\n",
      "          4.2667e-01,  8.6932e-01, -3.0771e-01, -6.5726e-01, -3.9648e-01,\n",
      "          5.8880e-01,  4.0051e-01, -6.8126e-01, -2.2121e-01, -4.7959e-01,\n",
      "         -5.6078e-01,  8.5208e-01,  2.3924e-01, -3.5869e-01, -4.7977e-01,\n",
      "         -6.9393e-02,  7.3849e-01,  8.2743e-01,  4.3272e-01, -7.2792e-01,\n",
      "          9.1052e-02, -7.6580e-01, -1.0074e-01,  3.7369e-01,  4.0541e-01,\n",
      "          2.9839e-01,  9.5846e-01,  6.0888e-01, -2.1023e-01, -7.7630e-01,\n",
      "         -9.2574e-01,  3.9160e-01, -7.3656e-01, -8.6151e-02, -3.7063e-01,\n",
      "         -9.7412e-03,  8.6905e-01, -3.1105e-01,  3.6491e-01, -9.0097e-01,\n",
      "         -4.8824e-01,  3.3087e-01, -6.7373e-02,  4.2973e-01, -3.7396e-01,\n",
      "         -4.7054e-01, -9.2874e-01, -4.4438e-01,  6.6564e-01,  5.8847e-01,\n",
      "          9.6799e-01, -3.4958e-01,  6.2778e-01, -3.3532e-01,  6.9853e-01,\n",
      "         -5.7256e-01,  4.9701e-01, -9.1648e-01, -3.0801e-01, -7.8099e-01,\n",
      "          8.6394e-01, -7.7224e-01,  7.5791e-01, -3.2464e-01, -8.4536e-01,\n",
      "         -8.8376e-01, -8.6617e-02,  3.2199e-01,  8.5573e-01, -3.0674e-01,\n",
      "          9.7196e-01,  5.0416e-01, -7.1158e-01,  6.9055e-01, -7.8167e-02,\n",
      "         -8.5584e-01, -8.9396e-01,  4.2054e-01, -9.0487e-01, -4.1618e-01,\n",
      "         -7.5912e-02, -7.6190e-01,  7.3555e-01,  3.5156e-01,  9.2117e-01,\n",
      "          4.1787e-01, -7.2370e-01,  6.9658e-03, -5.9750e-01,  2.3513e-01,\n",
      "         -3.7213e-02,  8.9918e-01,  1.4496e-01, -8.8571e-01,  4.8427e-01,\n",
      "          3.3279e-01,  3.2441e-01,  9.6002e-01,  9.5772e-01, -9.6184e-01,\n",
      "          9.1587e-01,  7.2189e-01,  6.3778e-01,  9.8248e-01,  1.4913e-01,\n",
      "          9.8056e-01,  9.3833e-01,  3.7830e-01, -8.4645e-01, -1.5841e-01,\n",
      "          2.9769e-01, -1.7500e-01, -3.6065e-01, -2.9723e-01, -7.7479e-01,\n",
      "         -7.7626e-01,  9.2620e-01,  9.0343e-01,  1.3457e-01,  4.8426e-01,\n",
      "          8.3857e-01,  4.9315e-02, -8.8050e-01,  2.7814e-02,  8.5382e-01,\n",
      "          1.0777e-01,  2.1667e-01, -3.1666e-01,  3.7520e-01,  8.9147e-01,\n",
      "         -6.6636e-01,  8.3669e-01,  8.5719e-01, -9.8172e-01,  3.7069e-01,\n",
      "         -2.2522e-01, -8.1772e-01, -6.9852e-01, -3.4567e-01, -1.8713e-01,\n",
      "         -8.4364e-01, -3.6418e-01, -6.3180e-01,  1.9399e-01,  2.4414e-01,\n",
      "          1.4064e-01, -5.7649e-01,  3.1220e-01, -8.3174e-01,  1.2187e-01,\n",
      "         -2.5941e-02, -7.4232e-01, -1.9690e-01, -9.7107e-02, -3.8780e-01,\n",
      "          7.3425e-01, -8.0583e-01,  9.0269e-01, -4.0012e-01, -8.5531e-01,\n",
      "         -1.1990e-02, -4.9700e-01, -6.3638e-01, -1.3133e-01,  2.2759e-01,\n",
      "          2.2032e-01,  2.2379e-01, -4.8592e-01, -8.9057e-01,  9.5263e-02,\n",
      "         -2.7237e-01, -3.2605e-01, -1.6522e-01,  9.0647e-01, -3.2112e-01,\n",
      "          6.8325e-01,  5.4094e-01,  7.7558e-01, -9.1780e-01, -9.8911e-01,\n",
      "         -7.7189e-01, -8.4389e-01,  8.6904e-01,  8.0407e-01,  4.6572e-01,\n",
      "         -4.1632e-02,  2.7735e-01,  6.0509e-01,  2.2910e-01, -8.9468e-01,\n",
      "          8.1312e-02,  3.4877e-01, -3.4582e-01,  7.5770e-01, -6.8698e-01,\n",
      "          1.0263e-01,  4.5231e-01,  4.5129e-01,  4.4626e-01, -9.5395e-01,\n",
      "          3.2812e-01, -3.1709e-01,  4.3928e-01, -4.4781e-01,  4.1952e-01,\n",
      "         -9.0755e-01, -4.3209e-01, -1.5560e-01,  5.2576e-02, -9.5818e-01,\n",
      "         -1.4202e-02, -4.1586e-01,  1.2104e-02,  1.7413e-01,  3.1562e-01,\n",
      "         -5.3077e-01, -5.0646e-01, -7.4578e-01, -7.1798e-01, -8.1281e-01,\n",
      "          4.4179e-01,  3.8790e-01, -3.3403e-01,  2.4737e-01,  1.5877e-01,\n",
      "          2.2838e-01, -2.0523e-01, -9.5239e-01,  3.5102e-01,  3.0619e-01,\n",
      "         -9.4506e-01,  8.2541e-01, -3.6251e-01, -1.1018e-01,  5.3803e-01,\n",
      "          9.3684e-01, -3.7245e-01, -4.7781e-01,  2.8598e-01, -5.7796e-01,\n",
      "         -2.6270e-01, -7.7679e-01,  8.4346e-01, -9.8109e-01,  3.5070e-01,\n",
      "          2.8960e-01, -6.8660e-01, -2.3731e-01,  5.9431e-01,  2.6608e-01,\n",
      "         -5.0789e-01,  7.6218e-01,  9.9183e-01, -3.2670e-01, -3.0673e-01,\n",
      "         -2.9354e-01,  9.4243e-01, -2.6843e-01,  3.8473e-01, -8.8784e-01,\n",
      "         -8.8051e-01, -6.4769e-01, -8.9226e-01, -9.4898e-01,  8.0328e-01,\n",
      "          3.4795e-01,  3.8869e-01,  9.5992e-01, -2.7655e-01, -3.8733e-01,\n",
      "         -1.3461e-01, -1.4734e-01, -7.9984e-01,  7.7240e-01, -5.0773e-01,\n",
      "          4.1681e-01, -3.9163e-01, -7.9342e-02, -9.3005e-01,  5.4652e-01,\n",
      "          9.5906e-01,  3.6672e-01, -2.8550e-01, -5.4461e-01,  2.7132e-01,\n",
      "         -5.1797e-01,  9.4526e-01, -4.0406e-01,  8.6194e-02, -2.3616e-01,\n",
      "         -8.8581e-01,  5.2355e-01,  3.8182e-01, -9.9758e-02,  4.3996e-01,\n",
      "         -9.6473e-01,  3.0597e-01,  9.0783e-01,  9.3739e-01, -7.8885e-01,\n",
      "         -3.8042e-01,  4.6843e-02, -9.2648e-01, -8.5406e-01,  3.2161e-01,\n",
      "         -6.0214e-01,  2.1603e-01, -3.2122e-01,  4.8463e-01,  9.8666e-01,\n",
      "         -2.1753e-01, -7.0951e-02, -3.8246e-01, -1.7897e-01, -4.1329e-01,\n",
      "         -6.6357e-01, -7.2539e-01,  5.0734e-01, -4.5858e-01, -9.3392e-01,\n",
      "          8.6655e-01, -7.5725e-01, -9.5612e-01,  3.2122e-01, -5.9686e-01,\n",
      "          8.2403e-02, -6.1286e-02, -4.3319e-01,  5.2182e-01, -3.8964e-01,\n",
      "         -4.3283e-01,  1.9368e-01,  4.3877e-01,  8.7862e-01, -3.7191e-01,\n",
      "         -8.4557e-01, -2.8015e-01,  3.7044e-01, -8.4876e-01, -9.7653e-01,\n",
      "         -4.6317e-01, -2.7606e-01, -1.0288e-01,  4.8955e-01,  8.2774e-01,\n",
      "          7.5921e-02, -9.0108e-01, -2.9429e-01, -2.5680e-02,  8.6237e-01,\n",
      "          4.2867e-01,  8.8865e-02, -7.7253e-01, -9.2510e-01, -7.7836e-01,\n",
      "          9.5740e-01, -8.5929e-01,  8.7684e-01, -9.3898e-01,  4.2007e-02,\n",
      "          2.7870e-01,  4.4470e-01, -8.3238e-01,  2.4579e-01, -1.3237e-01,\n",
      "          3.2073e-01,  7.3511e-01,  1.2002e-01, -8.6115e-01, -3.4530e-01,\n",
      "         -3.5762e-01,  3.3518e-01, -4.2905e-01,  5.9867e-01,  3.8028e-01,\n",
      "          4.3544e-01,  1.6721e-01, -4.2628e-01, -2.9423e-01,  3.5074e-01,\n",
      "          3.0537e-01, -5.4114e-01, -2.8940e-01,  2.8163e-01, -4.3224e-01,\n",
      "         -7.3053e-01, -1.8883e-01, -2.0200e-01,  9.7381e-01,  4.2870e-01,\n",
      "          8.5349e-03, -7.3745e-01, -7.7270e-01, -3.7393e-01,  6.2137e-01,\n",
      "         -1.9992e-01, -6.8555e-01, -4.1057e-01,  9.0544e-01,  8.8321e-01,\n",
      "          4.1003e-01, -1.8164e-01,  3.4765e-01, -2.6622e-01,  1.4129e-01,\n",
      "         -2.8681e-01,  1.6989e-01,  5.6514e-01,  6.3574e-01, -3.8036e-01,\n",
      "          3.1659e-01,  2.4431e-01, -3.8427e-02, -8.9254e-01,  3.6542e-01,\n",
      "         -3.8762e-01, -9.5964e-01, -7.2312e-01, -8.0696e-01,  2.9201e-01,\n",
      "          4.0530e-02, -5.7317e-01,  3.0644e-01,  3.7048e-01, -6.1288e-02,\n",
      "          9.4380e-01,  8.7382e-01,  7.2250e-01,  1.7084e-01,  2.9141e-02,\n",
      "         -4.7355e-01, -1.4446e-01,  3.2509e-01, -9.6676e-01,  9.3785e-01,\n",
      "          1.7642e-04,  6.7467e-01,  4.6546e-01,  3.5564e-01,  8.4591e-01,\n",
      "          3.0635e-01,  4.6182e-01,  1.7040e-01, -2.6809e-01,  3.5162e-01,\n",
      "         -7.6682e-01,  4.1134e-01, -9.3253e-01, -4.5084e-01, -8.5929e-01,\n",
      "          3.9825e-01,  1.9961e-01,  6.0731e-01, -4.1719e-01,  8.5338e-01,\n",
      "          9.4752e-01,  3.6543e-01,  6.1027e-01,  9.0086e-01,  4.0294e-01,\n",
      "         -7.2210e-01, -9.2557e-01, -9.3810e-01, -2.5208e-01, -5.1515e-01,\n",
      "         -3.5868e-01,  5.3267e-01,  4.2272e-01,  3.9193e-01,  3.0258e-01,\n",
      "          7.7464e-01,  7.2004e-01,  3.4849e-01, -9.4517e-01,  8.2127e-01,\n",
      "         -2.0387e-01, -2.0637e-01,  3.3701e-01, -9.3603e-01, -8.0605e-01,\n",
      "         -4.0347e-01, -3.7658e-01,  4.8935e-01,  3.9550e-01,  6.0081e-01,\n",
      "          1.7130e-01, -5.9993e-01,  9.6072e-02,  8.0500e-01,  1.6421e-01,\n",
      "         -9.4286e-01,  4.0870e-01,  7.4126e-01, -8.3158e-01,  8.5765e-01,\n",
      "         -5.0463e-01, -4.5610e-01,  8.0404e-01,  7.8484e-01,  7.7297e-01,\n",
      "          3.0962e-01,  3.9653e-01,  3.8659e-01,  3.9091e-01,  6.8671e-01,\n",
      "          8.4152e-01,  9.3267e-01,  8.9755e-01,  4.2040e-01,  8.7861e-01,\n",
      "          1.7500e-01, -1.3421e-01, -7.3546e-01,  2.9387e-01, -3.3535e-01,\n",
      "          2.3201e-01,  2.9523e-01, -3.0344e-01, -8.1592e-01,  2.6497e-02,\n",
      "         -1.7951e-01,  9.9865e-02, -5.1723e-01, -1.1553e-01, -4.3838e-01,\n",
      "         -4.2938e-01, -3.6703e-01,  1.5104e-01,  1.0656e-02,  7.3862e-02,\n",
      "          7.7764e-01, -7.0295e-01, -3.2328e-01, -1.3792e-01, -6.1139e-02,\n",
      "          8.8942e-01, -7.4525e-01,  6.7987e-01, -2.2802e-01,  6.4011e-01,\n",
      "         -8.8725e-01,  8.4696e-02,  1.1066e-01, -2.8854e-01, -3.3620e-01,\n",
      "         -3.2939e-01, -5.6244e-01,  6.0496e-01,  3.6628e-01, -3.9835e-01,\n",
      "         -1.4821e-01,  2.9668e-01,  4.7700e-01, -9.8115e-01,  8.5035e-01,\n",
      "          9.0089e-01,  3.1805e-01, -7.6244e-02,  2.9656e-01,  8.4649e-04,\n",
      "          7.8571e-01,  5.0442e-01,  5.4509e-01, -7.8914e-01,  6.3591e-01,\n",
      "         -9.3785e-01,  3.9846e-01, -8.5322e-01, -2.1293e-01, -7.1876e-01,\n",
      "         -8.3727e-01, -6.0344e-01,  2.5340e-01, -1.6334e-01,  6.9615e-01,\n",
      "         -9.4082e-01,  7.2528e-01,  5.3288e-01,  6.8240e-01, -1.1514e-01,\n",
      "          8.6052e-01, -5.3723e-01,  6.4740e-01]], device='cuda:0',\n",
      "       grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model_c_t     = AutoModel.from_pretrained(model_path)\n",
    "model_c_t.to('cuda')\n",
    "print(model_c_t(encoded_question_v['input_ids'][0:1].to('cuda')).pooler_output.to('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pekpsb8PCzaI"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7nCmI7WXhKTp"
   },
   "outputs": [],
   "source": [
    "      \n",
    "def shuffle(c:torch.tensor, q:torch.tensor): \n",
    "  idx = torch.randperm(q.shape[0])\n",
    "  permuted_c = c[idx].view(c.size())\n",
    "  permuted_q = q[idx].view(q.size())\n",
    "  return permuted_c, permuted_q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4_xPNH8uhKQ1"
   },
   "outputs": [],
   "source": [
    "light_contexts_v  = list(set(squad_dataset['validation']['context']))  # we only need 1 context per question \n",
    "questions_v       = squad_dataset['validation']['question']\n",
    "contexts_v        = squad_dataset['validation']['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PnkDppmo1i99"
   },
   "outputs": [],
   "source": [
    "import random as random \n",
    "index = [random.randint(0,1000) for i in range(100)]\n",
    "light_context_v   = [ context_v[i] for i in index]\n",
    "light_questions_v = [ questions_v[i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "TlCe98mzzYSJ",
    "outputId": "803259c4-cd5e-4cac-a849-7869e5c60ec7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "encoded_context_v  = tokenizer(light_context_v, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "\n",
    "encoded_question_v = tokenizer(light_questions_v, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "RM6hDrZ7zg27"
   },
   "outputs": [],
   "source": [
    "# context dictionnairy \n",
    "contexts_to_idx = dict()\n",
    "for id, context in enumerate(light_context_v):\n",
    "    contexts_to_idx[context] = id\n",
    "# question dictionnairy \n",
    "questions_to_ctx_idx = dict()\n",
    "for id, question in enumerate(light_questions_v):\n",
    "    questions_to_ctx_idx[id] = contexts_to_idx[context_v[id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LMDYYmngzqyj",
    "outputId": "55a841a6-0d2b-446f-f938-5c12c5eccd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Nr6-Lvgezsh3",
    "outputId": "2e44b298-bf4a-4de6-a890-f9c051129c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.7/dist-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "import faiss\n",
    "index         = faiss.IndexFlatIP(416)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "i_XwQFLe0g8_",
    "outputId": "27668068-9bcb-4a77-9742-213e24d7eb66"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-743a9154c849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlight_context_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_DRP_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_context_v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m    \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_put\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mreplacement_add\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path_q = '/content/gdrive/MyDrive/model/Bert_DRP_q'\n",
    "model_path_c = '/content/gdrive/MyDrive/model/Bert_DRP_c'\n",
    "\n",
    "\n",
    "model_DRP_c = AutoModel.from_pretrained(model_path_c).to('cuda')\n",
    "model_DRP_q = AutoModel.from_pretrained(model_path_q).to('cuda')\n",
    " \n",
    "batch_size = 14\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(0, len(light_context_v),batch_size )):\n",
    "   out_put = model_DRP_c(encoded_context_v['input_ids'][i:i+batch_size].to('cuda')).pooler_output.to('cuda')\n",
    "   index.add(out_put)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IH6Dzne1Uq_"
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "right_guesses = 0\n",
    "total_guesses = 0\n",
    "j=0\n",
    "for question in tqdm(light_questions_v):\n",
    "    encoded_question_v = tokenizer(question, \n",
    "                             padding=True, \n",
    "                             truncation=True, \n",
    "                             return_tensors='pt')\n",
    "    input_ids_q = encoded_question_v[\"input_ids\"]\n",
    "    embeddings_q = model_DRP_q(input_ids_q)\n",
    "    scores = index.search(embeddings_q[1].detach().numpy(), k)\n",
    "    print(context_index)\n",
    "    context_index = questions_to_ctx_idx[j]\n",
    "    #print(context_index)\n",
    "    if context_index in scores[1][0].tolist():\n",
    "        right_guesses+=1\n",
    "     \n",
    "    total_guesses+=1\n",
    "    j+=1\n",
    "print(\"\")\n",
    "print(\"Recall@10: \"+str(right_guesses/total_guesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XBYqLLvueKv"
   },
   "source": [
    "> **Problem 4.2** *(2 points)* Now that we have an MRC model and a retrieval model, if you want to create a open-domain QA system, you can simply connect them! Don't code, but describe in a few sentences how you will connect them and list two things that you need to be careful about (e.g. bias, inference speed, memory, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0yEXF7Bqj1D"
   },
   "source": [
    "_Case 1_ : We know the context : \n",
    "In this case, we slip the context in different parts, for example , we can split it for each sentences. Then we use the MRC to find the sentence with the greatest similarity with this question. When we have find the precise part which answer the question, we use T5 or BERT to answer the question more precicely. Like that we could avoid the answer similar that might be true but which are not (due to similarity in word eg : Place nane or locations. \n",
    "\n",
    "_Case 2_ : We don't know the context\n",
    "In that case you use the MRC to find the right context in the series of documents which can answer the problem. Then we use this context with T5 or BERT to retreive the answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prSYu-WwCsIz"
   },
   "source": [
    "# Test  - Garbadge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "QNE_bXqw2CDX",
    "outputId": "63227dc6-244e-4dd2-9c6a-583a6b06319f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6fa4de9e8813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSquadModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\" class with create the all dataset with the training and validation frames \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   def __init__(\n\u001b[1;32m      4\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtrain_dataframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class SquadModule(pl.LightningDataModule): \n",
    "  \"\"\" class with create the all dataset with the training and validation frames \"\"\"\n",
    "  def __init__(\n",
    "      self, \n",
    "      train_dataframe: pd.DataFrame,\n",
    "      validation_dataframe: pd.DataFrame,\n",
    "      tokenizer : T5Tokenizer, \n",
    "      batch_size : int = 6,\n",
    "      len_max_token_source : int = 396,\n",
    "      len_max_token_target : int = 40,\n",
    "  ):\n",
    "    super().__init__()\n",
    "    self.train_dataframe = train_dataframe\n",
    "    self.validation_dataframe = validation_dataframe\n",
    "    self.batch_size = batch_size\n",
    "    self.tokenizer = tokenizer\n",
    "    self.len_max_token_source = len_max_token_source\n",
    "    self.len_max_token_target = len_max_token_target\n",
    "\n",
    "  def setup (self): \n",
    "    self.train_dataset = SquadDataset (\n",
    "        self.train_dataframe, \n",
    "        self.tokenizer ,\n",
    "        self.len_max_token_source ,\n",
    "        self.len_max_token_target \n",
    "    )\n",
    "    self.validation_dataset = SquadDataset(\n",
    "        self.validation_dataframe, \n",
    "        self.tokenizer ,\n",
    "        self.len_max_token_source ,\n",
    "        self.len_max_token_target\n",
    "    )\n",
    "\n",
    "  def train_dataloader(self): \n",
    "    return DataLoader(\n",
    "      self.train_dataset, \n",
    "      batch_size = self.batch_size, \n",
    "      shuffle = True, \n",
    "      num_workers = 4\n",
    "    )\n",
    "  \n",
    "  def validation_dataloader(self): \n",
    "    return DataLoader(\n",
    "      self.validation_dataset, \n",
    "      batch_size = 1, \n",
    "      num_workers = 4\n",
    "    )\n",
    "\n",
    "  def test_dataloader(self): \n",
    "    return DataLoader(\n",
    "      self.validation_dataset, \n",
    "      batch_size = 1, \n",
    "      num_workers = 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kH0PqxV0_Y3O"
   },
   "outputs": [],
   "source": [
    "epoch_number = 6\n",
    "batch_size   = 2\n",
    "\n",
    "# creation of the dataset \n",
    "data_module  = SquadModule(train_dataframe, validation_dataframe, \n",
    "                           tokenizer, batch_size=batch_size)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d841fc6b76db4b28bfb4c28c25c4fdae",
      "e5a15c09785a49fb983ea28be8cb8162",
      "8ff47a26e757400c8656cf9e439f431f",
      "7f73cc4793ec48a9a9e7adf1178a752c",
      "29c41d98302d40dbb6a7158c88cb4f2a",
      "56a8f81958f648ac9443a7f8f97d6cc0",
      "9803cf472b9b424bb608f8b077b74c42",
      "88fbc12e05254f2cb0eaa4c764e1ccf6",
      "c4055eea347245d1895ded051ef9d83c",
      "36e80622456c4661a39abf48d6481165",
      "7fe7edb9c6784985a93043645ab0a7a9"
     ]
    },
    "id": "ZwdwsHNqC_6U",
    "outputId": "37db3a85-45b2-4fe5-d910-8933f8c4f30b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d841fc6b76db4b28bfb4c28c25c4fdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0enmFl2HEYuR"
   },
   "outputs": [],
   "source": [
    "class SquadQA(pl.LightningModule):\n",
    "  \n",
    "  def __init__(self): \n",
    "    super().__init__()\n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels = None ): \n",
    "    print(\"a\", input_ids)\n",
    "    output = self.model(\n",
    "        input_ids = input_ids, \n",
    "        attention_mask = attention_mask, \n",
    "        labels= labels\n",
    "    )\n",
    "    return output.loss, output.logits\n",
    "\n",
    "  def training_step(self, batch, index_batch):\n",
    "    input_ids      = batch [\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\" ]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs  = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"train_loss\", loss, prog_bar= True, logger =True)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, index_batch):\n",
    "    input_ids      = batch [\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\" ]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs  = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"val_loss\", loss, prog_bar= True, logger =True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, index_batch):\n",
    "    input_ids      = batch [\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\" ]\n",
    "    labels = batch[\"labels\"]\n",
    "    loss, outputs  = self(input_ids, attention_mask, labels)\n",
    "    self.log(\"test_loss\", loss, prog_bar= True, logger =True)\n",
    "    return loss\n",
    "\n",
    "  def optim_setup(self): \n",
    "    return AdamW(self.parameters(), lr=0.0001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMHKMQFDL-zy"
   },
   "outputs": [],
   "source": [
    "model = SquadQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbSq3rirL-PL"
   },
   "outputs": [],
   "source": [
    "# we stave the best check point at each times\n",
    "checkpoint_saver = ModelCheckpoint(\n",
    "    dirpath  = \"checkpoints\", \n",
    "    filename = \"best-check\", \n",
    "    save_top_k = 1, \n",
    "    verbose    = True, \n",
    "    monitor    = \"val_loss\", \n",
    "    mode       = \"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUP0XEpKNS8S",
    "outputId": "e39a7bfe-9f0c-49da-e94d-dc1a68c64a48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fe7ab84a4d0>)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7fe7ab84a4d0>)`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    checkpoint_callback = checkpoint_saver, \n",
    "    max_epochs          = epoch_number, \n",
    "    gpus                = 1, \n",
    "    progress_bar_refresh_rate= 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8IrGnJeGTW92",
    "outputId": "1c0b93de-61f3-4fcb-df1d-abc530879406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a SquadQA(\n",
      "  (model): T5ForConditionalGeneration(\n",
      "    (shared): Embedding(32128, 768)\n",
      "    (encoder): T5Stack(\n",
      "      (embed_tokens): Embedding(32128, 768)\n",
      "      (block): ModuleList(\n",
      "        (0): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (relative_attention_bias): Embedding(32, 12)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (decoder): T5Stack(\n",
      "      (embed_tokens): Embedding(32128, 768)\n",
      "      (block): ModuleList(\n",
      "        (0): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (relative_attention_bias): Embedding(32, 12)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (11): T5Block(\n",
      "          (layer): ModuleList(\n",
      "            (0): T5LayerSelfAttention(\n",
      "              (SelfAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (1): T5LayerCrossAttention(\n",
      "              (EncDecAttention): T5Attention(\n",
      "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
      "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (2): T5LayerFF(\n",
      "              (DenseReluDense): T5DenseReluDense(\n",
      "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
      "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (relu_act): ReLU()\n",
      "              )\n",
      "              (layer_norm): T5LayerNorm()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layer_norm): T5LayerNorm()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3e31cb5568d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-6c5bd752f9b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1608\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m             )\n\u001b[1;32m   1612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModelOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    924\u001b[0m             )\n\u001b[1;32m    925\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1186\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SquadQA' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "trainer.fit-model (model, data_module )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdsDSk07V5-B"
   },
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVK4Dk7wV_P8"
   },
   "outputs": [],
   "source": [
    "### Test \n",
    "trained_model = SquadQA.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M60prHhCW-oq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJSpk_rYL6xQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71Wzb_tYCrrp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "--PzT0K86T5p",
    "b6KSHZ-16YDJ",
    "6CEeXYKV6g6n",
    "YHeP0QSc6l5n",
    "5g7r-BmggWp5",
    "AYrslIhwKEJ_",
    "7g-UxStTeL9C",
    "JtMxV11iXn99",
    "Ktb-PmZpXjJN",
    "RPluisbsXd5a",
    "27pnaWWJakPy",
    "0G8ae2j-aeBN",
    "CLs6JK0zZKhv",
    "z_FFvO3obSX1",
    "1qsaoenFb15l",
    "KZEIhfk4b4VA",
    "ru3PlJcyPD72"
   ],
   "name": "Copie_de_KAIST_AI605_Assignment_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00429985e01b4defa60d016752c7ae79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "043aab8b054845e48ad3f16effc4b920": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05107c3bb3d64e89b1bc04fcd5634568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a02fafb2aabc44df965b67da26a2ad0d",
      "placeholder": "​",
      "style": "IPY_MODEL_d22a8daa094f474fb9cb677214bcd16e",
      "value": "Downloading: 100%"
     }
    },
    "070b180fb58a4de8b6e78ed1573efd8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07169dfe8c4b4e0f86438e7f04f9fc02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdcbb98dbef44e99a59ee3f6fefa26e3",
      "placeholder": "​",
      "style": "IPY_MODEL_5cbfee70b03a4e42aaa29d64793b4990",
      "value": " 570/570 [00:00&lt;00:00, 15.4kB/s]"
     }
    },
    "07704fb767104911a99b87af341d317f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0775621783564bee9d298bfcd8b199b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_decdf34e46064812b8a79e2af61bc883",
       "IPY_MODEL_e4bbb4323e4f4dcab527d31760317f1d",
       "IPY_MODEL_22ccb831100e419895b68b3ef6e1dc94"
      ],
      "layout": "IPY_MODEL_d4e018985d484fcba4759af009d113f8"
     }
    },
    "082fefda297046da890a35d56a384db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0906b302849f4f8fae7121b35c9db9e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fee7701d21ad4bffbbd31bd0605bc6c8",
      "placeholder": "​",
      "style": "IPY_MODEL_4588b2549d424120bccd3e8fd4b331d7",
      "value": " 2/2 [00:00&lt;00:00,  7.18it/s]"
     }
    },
    "09d49858f34a43188ab12e66da323645": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bfbc1ffb4624f03a977a180db6b7dce",
       "IPY_MODEL_7bba2cf8db6446cb9f98e5e9fbd7c83f",
       "IPY_MODEL_b1ecd6d56b9d407b9e6198eb317fd030"
      ],
      "layout": "IPY_MODEL_e9413b98ae6643e2b478ec3087aad8d7"
     }
    },
    "0dae339ea5b046c0947c4d9b7a91843e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ef3824c3f2e4f2797cc5c072f300ec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e6017dec08463e86e5aacbd70d08a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11f64f8841454935b3eb8d6a19e71d5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12e62a3bcde94140b16e8e37420b907c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73d2f754a31640659e7aa4d45bb255e2",
      "placeholder": "​",
      "style": "IPY_MODEL_9f5db1c3f5d84bf4a00f2acc5f24db8e",
      "value": " 1.32M/1.32M [00:00&lt;00:00, 15.1MB/s]"
     }
    },
    "12f9bb884a204ea2a03c941290c0cae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1399ead84a2f45aea0160d86de31cd60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68a4b8e98f5441bb840ce429ae675abc",
       "IPY_MODEL_d6603dabc5a745e8a6e683073adbdb89",
       "IPY_MODEL_9d53ca1058454bbdba98ecf7a315241b"
      ],
      "layout": "IPY_MODEL_a46e3eb5afe24660a4f84f2271e0b2d0"
     }
    },
    "155a02655273460db835d0504daafbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15f63fac24a64429ac78e447800998a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f00b3067ced4efe9e116a6b567a8cfd",
      "placeholder": "​",
      "style": "IPY_MODEL_d86aa849c4da479ba41be23dec5a0372",
      "value": " 416M/416M [00:07&lt;00:00, 57.9MB/s]"
     }
    },
    "1605d3bf111845c58df7386f1d1be60e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "16de154b4eb543c7966079ab84f4853b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f3393ddb6a74668b9f189e19d6911c7",
       "IPY_MODEL_9d49a74ca9af4e78b331b9a755d7c15f",
       "IPY_MODEL_0906b302849f4f8fae7121b35c9db9e4"
      ],
      "layout": "IPY_MODEL_f32d2bb8c2a744e6b00e164ef74a1d2a"
     }
    },
    "17aa731a6dbe43c69fd97748b39b7353": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1ae172d9e9247d8b07034daada09ae0",
      "placeholder": "​",
      "style": "IPY_MODEL_e8e81c31c5a84b66ae3677fc1e474abb",
      "value": " 231M/231M [00:06&lt;00:00, 39.0MB/s]"
     }
    },
    "18d6f44f041d4f28aa6253facfc1440c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1bc7cb4462fe4190b654ff4819d46b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6aac9ba5650c47f48aba0cb78c0d8486",
      "placeholder": "​",
      "style": "IPY_MODEL_2655501bef124208aefff1e732a40432",
      "value": " 399/399 [00:00&lt;00:00, 7.85kB/s]"
     }
    },
    "1c0e7d8d4eab44649532132e8fbef185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bbb9df619ce43509589cd7996bf25a9",
       "IPY_MODEL_2f7b5a3377cb4ffb88738ee1188d4b3c",
       "IPY_MODEL_b89d583acf174b3aa7ef8201a6195e69"
      ],
      "layout": "IPY_MODEL_0dae339ea5b046c0947c4d9b7a91843e"
     }
    },
    "1c0f3efb519946e1ae3474c8166d012d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c1f3720962a4559b0976fa598ab1f24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1308830d5fa4296aac76885e62d17a2",
      "max": 1197,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b04ce181d35144718b3e8dda3c7f5c33",
      "value": 1197
     }
    },
    "1c5d145d73d34673859f5883531c9d8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d8ee50f0c9c4264ac26fdaf18978d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1f29dccde956435783fceaa35908f348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20bd851c682f415eb276d0f5bf42fa3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81539b6089144f7fa15e5ddf9d7031ef",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a60e090289d47cda36ff4d04e015480",
      "value": 213450
     }
    },
    "22ccb831100e419895b68b3ef6e1dc94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edb27b27e75e482d9cdbd1eeebed8ee6",
      "placeholder": "​",
      "style": "IPY_MODEL_4097b168f3f548f6ba1a3fa10d32909b",
      "value": " 418M/418M [00:07&lt;00:00, 57.3MB/s]"
     }
    },
    "233997f8a5f040b3bc9b5cab1dc0fd06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ec27e8f6478434f89d89576aaadc677",
      "placeholder": "​",
      "style": "IPY_MODEL_aa74be5f8d91493ba592dd59af95af43",
      "value": " 226k/226k [00:00&lt;00:00, 1.05MB/s]"
     }
    },
    "233a192d4fd94a19badc772de8462a78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2655501bef124208aefff1e732a40432": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "273ef8651a9349e6ac45ae5a6e7b6955": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "274c840571304321bda7f84b4f0a1b74": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2835612c1da24bc1b75fb58e50524a1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c41d98302d40dbb6a7158c88cb4f2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a98440904c1411ebe15f36cb0aff226": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1ebb88661ca4bd59455e5aa6ffadcdf",
       "IPY_MODEL_d52b2b451a3a4b9bbfbd61aee9499229",
       "IPY_MODEL_dc03d053690f4c0d832e9c9ef906cacd"
      ],
      "layout": "IPY_MODEL_2b103f6133ac42ffbe9d61f5d2c09d31"
     }
    },
    "2b103f6133ac42ffbe9d61f5d2c09d31": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bd6eedbaeab4250a0086c8c68ba4f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b46b9b7125c42ad84619c8b1f435c3d",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1605d3bf111845c58df7386f1d1be60e",
      "value": 231508
     }
    },
    "2d94480937074562904cf04374f75963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f37877ed50e84deba26a177aa0ad6b2b",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e6fb4bfb4816475497ca11d03087aa20",
      "value": 791656
     }
    },
    "2dd14af33437453b851229608a03b31f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f6e070234f149cdb068ddde24be7604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c0f3efb519946e1ae3474c8166d012d",
      "placeholder": "​",
      "style": "IPY_MODEL_375064928e2741639ef75998eefb7f64",
      "value": "Downloading: 100%"
     }
    },
    "2f7b5a3377cb4ffb88738ee1188d4b3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afcb28732f1942319a06825e944cf651",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31a16315960c415f8cd32e5d3439b18f",
      "value": 2
     }
    },
    "2fcf87010fed45ba83e14ef416573596": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30326e316b8d4d51ac538224f73c103d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30c9d8da7ee340aea68182022cf750ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3110feb0609748f9b48243988c13f824": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a16315960c415f8cd32e5d3439b18f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33e1abbb6804466a9ba5e40f9ea6b5e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34e764c4a2244c5baf9b401a60055c9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42ce59cf162648339ee635983e26d8ba",
      "placeholder": "​",
      "style": "IPY_MODEL_b969f6c49c2a4b26879ecce84a67cee0",
      "value": "Downloading builder script: "
     }
    },
    "36716f24b1f34f93904d11e0b7043451": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f11e0e838784079afdd0b0ca8c2757c",
      "max": 1389353,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a720c51460fa4362982c8c5e00de9f5c",
      "value": 1389353
     }
    },
    "367ffeab7c8b48038aa3f6f044d00810": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36e80622456c4661a39abf48d6481165": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "375064928e2741639ef75998eefb7f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3af54e1f442f492383d3c4bb44849283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f3393ddb6a74668b9f189e19d6911c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab27e5bab14e4af8aa5d93361951ea4f",
      "placeholder": "​",
      "style": "IPY_MODEL_1f29dccde956435783fceaa35908f348",
      "value": "100%"
     }
    },
    "4097b168f3f548f6ba1a3fa10d32909b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40b7f13935d14b1ca1feba12a61ff566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_779f8f9141734117bf30c4313bddfd16",
      "placeholder": "​",
      "style": "IPY_MODEL_dc06666761f34cafaa45cbc20b0b3208",
      "value": " 1.17k/1.17k [00:00&lt;00:00, 28.2kB/s]"
     }
    },
    "42a52e4894614038b10d7fa6a1a5bad9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "42ce59cf162648339ee635983e26d8ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44d435e8d74b4f76998be410afd34091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5e74c666ba64ef4b991668f303ebea7",
       "IPY_MODEL_f3fe6711b9da46f7b713ff79794b18bb",
       "IPY_MODEL_b77945171d7448e0b752f0ffabb22e5c"
      ],
      "layout": "IPY_MODEL_fe43c1d2776347b7bdba864e82c865cc"
     }
    },
    "4588b2549d424120bccd3e8fd4b331d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "466bca6a7696473daabac92cb9b03bbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "471d168f549447ffbb5b009f830cf831": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a60e090289d47cda36ff4d04e015480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4b46b9b7125c42ad84619c8b1f435c3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b7e7b0fa0d043ccb287b2f849df6d20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_273ef8651a9349e6ac45ae5a6e7b6955",
      "placeholder": "​",
      "style": "IPY_MODEL_00429985e01b4defa60d016752c7ae79",
      "value": "Downloading: 100%"
     }
    },
    "4cec98c851f4486692d7f709f3839aed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "530e561f1f724861946de2e2b5774f76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "558712d9f1724d99a62a027b8360ad9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56a8f81958f648ac9443a7f8f97d6cc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56f0f76a767f43e0865552fe4096b582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_985db720fd88436488815255f353abee",
      "placeholder": "​",
      "style": "IPY_MODEL_738b31eca10342acac8cf76270212c2c",
      "value": "Downloading: 100%"
     }
    },
    "57a8c5ce35f643c6b25a74c88d8d4ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "593cd37ef15c41f9a69706ebd3e7441a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b7e7b0fa0d043ccb287b2f849df6d20",
       "IPY_MODEL_ddcf6219e54b45a4855c8c6c2514c96f",
       "IPY_MODEL_40b7f13935d14b1ca1feba12a61ff566"
      ],
      "layout": "IPY_MODEL_5fbf5c449e804ef0b14d01a0350cf425"
     }
    },
    "5ae82c3eb87c4c81a1daa34419590a5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ca8bd2a2b1846c0ba1cced8431f185e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cbfee70b03a4e42aaa29d64793b4990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f00b3067ced4efe9e116a6b567a8cfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f5b3249800745ab90c48d7ec2cda01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fbf5c449e804ef0b14d01a0350cf425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6083ca67e00b4866aafc60e90f84c60c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "619dc782eb834296b09c462e132ae20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_471d168f549447ffbb5b009f830cf831",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d8ee50f0c9c4264ac26fdaf18978d5a",
      "value": 570
     }
    },
    "61f45d81147a40eba63f13ac64b2ae9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_274c840571304321bda7f84b4f0a1b74",
      "placeholder": "​",
      "style": "IPY_MODEL_89c98d6cc4b541bb899258d3c0b0d864",
      "value": "Downloading: 100%"
     }
    },
    "63cf8ff7f6854461b5ea59e48f0eaf80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2835612c1da24bc1b75fb58e50524a1d",
      "max": 1715,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18d6f44f041d4f28aa6253facfc1440c",
      "value": 1715
     }
    },
    "641b99152d3c4a0b995042bb147896ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "647b34db9c0744b3a8023973637b1dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f90b9613bcf43b9bac7b764c77f0df7",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42a52e4894614038b10d7fa6a1a5bad9",
      "value": 2
     }
    },
    "65ec9ae5f1b9406f991b9ee3dfbf4705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_641b99152d3c4a0b995042bb147896ca",
      "placeholder": "​",
      "style": "IPY_MODEL_76516639ce714d2cae89d3e2b875acdb",
      "value": " 1.17k/1.17k [00:00&lt;00:00, 18.3kB/s]"
     }
    },
    "663d733e19f04acbaf15950016f9ae86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68a4b8e98f5441bb840ce429ae675abc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea3882d0f83c46cc8d255d69c981cc4c",
      "placeholder": "​",
      "style": "IPY_MODEL_899ff58b5aae44279c1438371615cba9",
      "value": "Downloading: 100%"
     }
    },
    "696651e4dc6741bf8475c87c7bf5ae11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6aac9ba5650c47f48aba0cb78c0d8486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab95d30bb3846e8b8fdff783bfa1d26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b17b0751cfb47109523569c101a8df5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bfbc1ffb4624f03a977a180db6b7dce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ef3824c3f2e4f2797cc5c072f300ec7",
      "placeholder": "​",
      "style": "IPY_MODEL_12f9bb884a204ea2a03c941290c0cae5",
      "value": "Downloading extra modules: "
     }
    },
    "6d3d3d4c3c79498e98a77b0a0cdc5df1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f11e0e838784079afdd0b0ca8c2757c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f337c72a32e4d46aac10af14bbcbd03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fdf672f2cb24de0acbdab12c6b4ea48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ca8bd2a2b1846c0ba1cced8431f185e",
      "placeholder": "​",
      "style": "IPY_MODEL_d336f39efec84b4d93883ed09a124098",
      "value": "Downloading: 100%"
     }
    },
    "6fe47d9b9db845cf8bc6953d328e0df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_884a6b743e1e48fa8b3e5df3e2be92f0",
      "placeholder": "​",
      "style": "IPY_MODEL_d1daa687779f44db83f04dbb85c4fe2b",
      "value": " 4.50k/? [00:00&lt;00:00, 119kB/s]"
     }
    },
    "712fe1d4ed644ef2b2184f6989a4e543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f6e070234f149cdb068ddde24be7604",
       "IPY_MODEL_9929aef74d85422fb016cb968a55c0c7",
       "IPY_MODEL_72464554e5cf4936ab6ba338d487e8aa"
      ],
      "layout": "IPY_MODEL_dccacf7c834b41119e3a4191a8801937"
     }
    },
    "72464554e5cf4936ab6ba338d487e8aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7fb8429b5844cf1a38b547c784b05f6",
      "placeholder": "​",
      "style": "IPY_MODEL_10e6017dec08463e86e5aacbd70d08a4",
      "value": " 625/625 [00:00&lt;00:00, 17.4kB/s]"
     }
    },
    "738b31eca10342acac8cf76270212c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73d2f754a31640659e7aa4d45bb255e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7410a3ce72b0419395f8f1e8471d5ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fea1ec5fd02460fa4a738fc5b180398",
       "IPY_MODEL_36716f24b1f34f93904d11e0b7043451",
       "IPY_MODEL_12e62a3bcde94140b16e8e37420b907c"
      ],
      "layout": "IPY_MODEL_5f5b3249800745ab90c48d7ec2cda01f"
     }
    },
    "76516639ce714d2cae89d3e2b875acdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "779f8f9141734117bf30c4313bddfd16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77b07f25d0cf411d81542413e7d51fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7928ab3ea0924c468ddb34fe14178cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0aa3b4f26ea4b71b81aa7f8f24c4be3",
       "IPY_MODEL_619dc782eb834296b09c462e132ae20d",
       "IPY_MODEL_07169dfe8c4b4e0f86438e7f04f9fc02"
      ],
      "layout": "IPY_MODEL_97bb563104394ac6a9f50e4411c39d5e"
     }
    },
    "7bba2cf8db6446cb9f98e5e9fbd7c83f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_155a02655273460db835d0504daafbc1",
      "max": 1119,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33e1abbb6804466a9ba5e40f9ea6b5e9",
      "value": 1119
     }
    },
    "7c98fc1e7e2449959776ffb59365bf5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f73cc4793ec48a9a9e7adf1178a752c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36e80622456c4661a39abf48d6481165",
      "placeholder": "​",
      "style": "IPY_MODEL_7fe7edb9c6784985a93043645ab0a7a9",
      "value": " 850M/850M [00:16&lt;00:00, 59.9MB/s]"
     }
    },
    "7f90b9613bcf43b9bac7b764c77f0df7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fe7edb9c6784985a93043645ab0a7a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8016369f04d94dd38774a56833c8679a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9898b387847641ce81a180b5abb8f937",
       "IPY_MODEL_ed937cd2a8cd4c37881a19285c78d78e",
       "IPY_MODEL_15f63fac24a64429ac78e447800998a1"
      ],
      "layout": "IPY_MODEL_e2f6a1b99d494104b6a8aaefaa834b6d"
     }
    },
    "81539b6089144f7fa15e5ddf9d7031ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "854b8fe9b94843668d05fc2755eabaf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "859044fcaebc416bb62c6057060c26b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "884a6b743e1e48fa8b3e5df3e2be92f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88fbc12e05254f2cb0eaa4c764e1ccf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "899ff58b5aae44279c1438371615cba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89c98d6cc4b541bb899258d3c0b0d864": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bbb9df619ce43509589cd7996bf25a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8de9136e5fdc4ddda38fa223b7dfe41f",
      "placeholder": "​",
      "style": "IPY_MODEL_b31736718a3a4189aafe3bca63ddf5be",
      "value": "100%"
     }
    },
    "8c1043b3eb684bc3835cb693102f4429": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cec068c0fe0403790b95f3b09f742e1",
      "placeholder": "​",
      "style": "IPY_MODEL_854b8fe9b94843668d05fc2755eabaf5",
      "value": " 2.00/2.00 [00:00&lt;00:00, 60.8B/s]"
     }
    },
    "8d7b717611ec40a6ae268455dd6b3d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8de9136e5fdc4ddda38fa223b7dfe41f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fdd2f684d76401eac5c6eddcc3aeca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05107c3bb3d64e89b1bc04fcd5634568",
       "IPY_MODEL_2d94480937074562904cf04374f75963",
       "IPY_MODEL_a50a15e2c12c4c77996cadde2cea6783"
      ],
      "layout": "IPY_MODEL_d49cd045d560480788f6b944a51fd992"
     }
    },
    "8fea1ec5fd02460fa4a738fc5b180398": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ae82c3eb87c4c81a1daa34419590a5c",
      "placeholder": "​",
      "style": "IPY_MODEL_6d3d3d4c3c79498e98a77b0a0cdc5df1",
      "value": "Downloading: 100%"
     }
    },
    "8ff47a26e757400c8656cf9e439f431f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88fbc12e05254f2cb0eaa4c764e1ccf6",
      "max": 891691430,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4055eea347245d1895ded051ef9d83c",
      "value": 891691430
     }
    },
    "97bb563104394ac6a9f50e4411c39d5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9803cf472b9b424bb608f8b077b74c42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "985db720fd88436488815255f353abee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9898b387847641ce81a180b5abb8f937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9d85fd1154242d683fa4c4f8d442f61",
      "placeholder": "​",
      "style": "IPY_MODEL_9eeb4d82161c4d82a04ce0433a4289dc",
      "value": "Downloading: 100%"
     }
    },
    "9929aef74d85422fb016cb968a55c0c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee7b45c4c4e44168836bf21f9f6022c9",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f337c72a32e4d46aac10af14bbcbd03",
      "value": 625
     }
    },
    "9cec068c0fe0403790b95f3b09f742e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d49a74ca9af4e78b331b9a755d7c15f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_466bca6a7696473daabac92cb9b03bbc",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c713cbf0b83c47c6accfe99f60afaf0d",
      "value": 2
     }
    },
    "9d53ca1058454bbdba98ecf7a315241b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dd14af33437453b851229608a03b31f",
      "placeholder": "​",
      "style": "IPY_MODEL_696651e4dc6741bf8475c87c7bf5ae11",
      "value": " 455k/455k [00:00&lt;00:00, 1.12MB/s]"
     }
    },
    "9ec27e8f6478434f89d89576aaadc677": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9eeb4d82161c4d82a04ce0433a4289dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ef2960cc03a4622b398eb95a38da4a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f5db1c3f5d84bf4a00f2acc5f24db8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a02fafb2aabc44df965b67da26a2ad0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2ffc6d9053d4d8facbe973fbc5bab1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6142f4f150e4313a8dab16931fc30a7",
      "placeholder": "​",
      "style": "IPY_MODEL_cf3adb491cd04ed0a25b326670161573",
      "value": "Downloading: 100%"
     }
    },
    "a3e0522c3bd54563998d13252419e96d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a46de8a958af4d8488256d7b522dfe5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a46e3eb5afe24660a4f84f2271e0b2d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a50a15e2c12c4c77996cadde2cea6783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07704fb767104911a99b87af341d317f",
      "placeholder": "​",
      "style": "IPY_MODEL_cc840f86eec04151a5e02fb80bfc0b9d",
      "value": " 773k/773k [00:00&lt;00:00, 7.85MB/s]"
     }
    },
    "a720c51460fa4362982c8c5e00de9f5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa74be5f8d91493ba592dd59af95af43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab27e5bab14e4af8aa5d93361951ea4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab983112a7414d43a24ba4d02a683105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_233a192d4fd94a19badc772de8462a78",
      "max": 399,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_530e561f1f724861946de2e2b5774f76",
      "value": 399
     }
    },
    "afcb28732f1942319a06825e944cf651": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b04ce181d35144718b3e8dda3c7f5c33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b11954568f7546aab33a028f2a4dafb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df735f4e4cad4c918724546bbffe5e91",
      "max": 242065649,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7b6cc7be6cb46748459e94ad46d9687",
      "value": 242065649
     }
    },
    "b13a512c5a2c4dd28ce4be5eaf916be8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1ebb88661ca4bd59455e5aa6ffadcdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0c1537770f8462ebe3cdb0723b3e154",
      "placeholder": "​",
      "style": "IPY_MODEL_6b17b0751cfb47109523569c101a8df5",
      "value": "Downloading: 100%"
     }
    },
    "b1ecd6d56b9d407b9e6198eb317fd030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_070b180fb58a4de8b6e78ed1573efd8e",
      "placeholder": "​",
      "style": "IPY_MODEL_859044fcaebc416bb62c6057060c26b5",
      "value": " 3.31k/? [00:00&lt;00:00, 89.6kB/s]"
     }
    },
    "b31736718a3a4189aafe3bca63ddf5be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b77945171d7448e0b752f0ffabb22e5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_043aab8b054845e48ad3f16effc4b920",
      "placeholder": "​",
      "style": "IPY_MODEL_d8342957072d4294ab13a2ea0e2114c1",
      "value": " 112/112 [00:00&lt;00:00, 2.70kB/s]"
     }
    },
    "b89d583acf174b3aa7ef8201a6195e69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e184eec8920a4da9aa71f89bf30eea14",
      "placeholder": "​",
      "style": "IPY_MODEL_57a8c5ce35f643c6b25a74c88d8d4ab9",
      "value": " 2/2 [00:00&lt;00:00, 22.96it/s]"
     }
    },
    "b969f6c49c2a4b26879ecce84a67cee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9d85fd1154242d683fa4c4f8d442f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba10ef5a093e4200a93f6ea466520683": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfda21f61f594f9db7d4f68bf59625cc",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab95d30bb3846e8b8fdff783bfa1d26",
      "value": " 208k/208k [00:00&lt;00:00, 1.35MB/s]"
     }
    },
    "ba5957d0c84b43ffafe40df615a1f397": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0c1537770f8462ebe3cdb0723b3e154": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4055eea347245d1895ded051ef9d83c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c5e74c666ba64ef4b991668f303ebea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3110feb0609748f9b48243988c13f824",
      "placeholder": "​",
      "style": "IPY_MODEL_8d7b717611ec40a6ae268455dd6b3d8d",
      "value": "Downloading: 100%"
     }
    },
    "c713cbf0b83c47c6accfe99f60afaf0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7cd19f054af485cb863d67f03b22961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc840f86eec04151a5e02fb80bfc0b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdad12534c844ca7ad3abf662a6284b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cdcbb98dbef44e99a59ee3f6fefa26e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cecedf48b3524fea85773056555b3be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30326e316b8d4d51ac538224f73c103d",
      "placeholder": "​",
      "style": "IPY_MODEL_ba5957d0c84b43ffafe40df615a1f397",
      "value": "Downloading: 100%"
     }
    },
    "cf3adb491cd04ed0a25b326670161573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d02dbe7dc6fe4974b940d980aeaa3fcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1308830d5fa4296aac76885e62d17a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d166f9d82eed4bdb824e1c8de20dfe65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56f0f76a767f43e0865552fe4096b582",
       "IPY_MODEL_2bd6eedbaeab4250a0086c8c68ba4f3c",
       "IPY_MODEL_233997f8a5f040b3bc9b5cab1dc0fd06"
      ],
      "layout": "IPY_MODEL_4cec98c851f4486692d7f709f3839aed"
     }
    },
    "d1b7124b55fc4a1fbd5f48a1531aef97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec6e21093ec04ee7845068c311eec4aa",
       "IPY_MODEL_1c1f3720962a4559b0976fa598ab1f24",
       "IPY_MODEL_65ec9ae5f1b9406f991b9ee3dfbf4705"
      ],
      "layout": "IPY_MODEL_558712d9f1724d99a62a027b8360ad9f"
     }
    },
    "d1daa687779f44db83f04dbb85c4fe2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2085fcc8e4849ae9c334712c738e522": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22a8daa094f474fb9cb677214bcd16e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d336f39efec84b4d93883ed09a124098": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d49cd045d560480788f6b944a51fd992": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4e018985d484fcba4759af009d113f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d52b2b451a3a4b9bbfbd61aee9499229": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c98fc1e7e2449959776ffb59365bf5c",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ef2960cc03a4622b398eb95a38da4a1",
      "value": 29
     }
    },
    "d6603dabc5a745e8a6e683073adbdb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11f64f8841454935b3eb8d6a19e71d5d",
      "max": 466081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdad12534c844ca7ad3abf662a6284b9",
      "value": 466081
     }
    },
    "d77fc2e965c44913900d4afc92a8ea7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34e764c4a2244c5baf9b401a60055c9c",
       "IPY_MODEL_63cf8ff7f6854461b5ea59e48f0eaf80",
       "IPY_MODEL_6fe47d9b9db845cf8bc6953d328e0df3"
      ],
      "layout": "IPY_MODEL_2fcf87010fed45ba83e14ef416573596"
     }
    },
    "d7fb8429b5844cf1a38b547c784b05f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8342957072d4294ab13a2ea0e2114c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d841fc6b76db4b28bfb4c28c25c4fdae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5a15c09785a49fb983ea28be8cb8162",
       "IPY_MODEL_8ff47a26e757400c8656cf9e439f431f",
       "IPY_MODEL_7f73cc4793ec48a9a9e7adf1178a752c"
      ],
      "layout": "IPY_MODEL_29c41d98302d40dbb6a7158c88cb4f2a"
     }
    },
    "d86aa849c4da479ba41be23dec5a0372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc03d053690f4c0d832e9c9ef906cacd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f145b7bb1ea34075bd86e7f223629fca",
      "placeholder": "​",
      "style": "IPY_MODEL_367ffeab7c8b48038aa3f6f044d00810",
      "value": " 29.0/29.0 [00:00&lt;00:00, 795B/s]"
     }
    },
    "dc06666761f34cafaa45cbc20b0b3208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dccacf7c834b41119e3a4191a8801937": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd5375cce8aa4ac5883a7c82be814954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61f45d81147a40eba63f13ac64b2ae9b",
       "IPY_MODEL_20bd851c682f415eb276d0f5bf42fa3d",
       "IPY_MODEL_ba10ef5a093e4200a93f6ea466520683"
      ],
      "layout": "IPY_MODEL_6083ca67e00b4866aafc60e90f84c60c"
     }
    },
    "ddcf6219e54b45a4855c8c6c2514c96f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_663d733e19f04acbaf15950016f9ae86",
      "max": 1199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_082fefda297046da890a35d56a384db0",
      "value": 1199
     }
    },
    "de23f543b15f454db25d491d8e6b2b81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "decdf34e46064812b8a79e2af61bc883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c5d145d73d34673859f5883531c9d8a",
      "placeholder": "​",
      "style": "IPY_MODEL_3af54e1f442f492383d3c4bb44849283",
      "value": "Downloading: 100%"
     }
    },
    "df32da84e69742a485fe29fc960c4194": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cecedf48b3524fea85773056555b3be3",
       "IPY_MODEL_b11954568f7546aab33a028f2a4dafb9",
       "IPY_MODEL_17aa731a6dbe43c69fd97748b39b7353"
      ],
      "layout": "IPY_MODEL_30c9d8da7ee340aea68182022cf750ea"
     }
    },
    "df735f4e4cad4c918724546bbffe5e91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfda21f61f594f9db7d4f68bf59625cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0aa3b4f26ea4b71b81aa7f8f24c4be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d02dbe7dc6fe4974b940d980aeaa3fcf",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cd19f054af485cb863d67f03b22961",
      "value": "Downloading: 100%"
     }
    },
    "e184eec8920a4da9aa71f89bf30eea14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f6a1b99d494104b6a8aaefaa834b6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e39f387e549e488ca353b92854b8c8f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fdf672f2cb24de0acbdab12c6b4ea48",
       "IPY_MODEL_647b34db9c0744b3a8023973637b1dde",
       "IPY_MODEL_8c1043b3eb684bc3835cb693102f4429"
      ],
      "layout": "IPY_MODEL_f8a3fc5d917e430490bf42324d5a2d83"
     }
    },
    "e4bbb4323e4f4dcab527d31760317f1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2085fcc8e4849ae9c334712c738e522",
      "max": 438007537,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f2683b3ee1fa47488e3486f02e7ac2fe",
      "value": 438007537
     }
    },
    "e5a15c09785a49fb983ea28be8cb8162": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56a8f81958f648ac9443a7f8f97d6cc0",
      "placeholder": "​",
      "style": "IPY_MODEL_9803cf472b9b424bb608f8b077b74c42",
      "value": "Downloading: 100%"
     }
    },
    "e6142f4f150e4313a8dab16931fc30a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6fb4bfb4816475497ca11d03087aa20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7b6cc7be6cb46748459e94ad46d9687": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8e81c31c5a84b66ae3677fc1e474abb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9413b98ae6643e2b478ec3087aad8d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea3882d0f83c46cc8d255d69c981cc4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebab440b46cd4e4b89568521db24284d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec6e21093ec04ee7845068c311eec4aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5609944cd08450db376a329af7a4029",
      "placeholder": "​",
      "style": "IPY_MODEL_a3e0522c3bd54563998d13252419e96d",
      "value": "Downloading: 100%"
     }
    },
    "ed937cd2a8cd4c37881a19285c78d78e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a46de8a958af4d8488256d7b522dfe5d",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ebab440b46cd4e4b89568521db24284d",
      "value": 435779157
     }
    },
    "edb27b27e75e482d9cdbd1eeebed8ee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee7b45c4c4e44168836bf21f9f6022c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f030d936921c4591a8ef3edba89b750c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2ffc6d9053d4d8facbe973fbc5bab1a",
       "IPY_MODEL_ab983112a7414d43a24ba4d02a683105",
       "IPY_MODEL_1bc7cb4462fe4190b654ff4819d46b52"
      ],
      "layout": "IPY_MODEL_de23f543b15f454db25d491d8e6b2b81"
     }
    },
    "f145b7bb1ea34075bd86e7f223629fca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1ae172d9e9247d8b07034daada09ae0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2683b3ee1fa47488e3486f02e7ac2fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f32d2bb8c2a744e6b00e164ef74a1d2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f37877ed50e84deba26a177aa0ad6b2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3fe6711b9da46f7b713ff79794b18bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b13a512c5a2c4dd28ce4be5eaf916be8",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77b07f25d0cf411d81542413e7d51fe4",
      "value": 112
     }
    },
    "f5609944cd08450db376a329af7a4029": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8a3fc5d917e430490bf42324d5a2d83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe43c1d2776347b7bdba864e82c865cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fee7701d21ad4bffbbd31bd0605bc6c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
